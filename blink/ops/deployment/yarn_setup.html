<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.5.1 Documentation: YARN Setup</title>
    <link rel="shortcut icon" href="//flink-china.org/doc/blink/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//flink-china.org/doc/blink/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/flink.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/syntax.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/codetabs.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          







  
    
    
    
      
    
  

  
    
    
    
      
    
  

  
    
    
    
      













<div class="sidenav-logo">
  <p><a href="//flink-china.org/doc/blink"><img class="bottom" alt="Apache Flink" src="//flink-china.org/doc/blink/page/img/navbar-brand-logo.jpg"></a> v1.5.1</p>
</div>
<ul id="sidenav">

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li>
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/concepts/programming-model.html">Programming Model</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-6" data-toggle="collapse"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-6"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse">API Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-7"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/datastream_api.html">DataStream API</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-10" data-toggle="collapse">Setup Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-10"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/local_setup.html">Local Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/setup_quickstart.html"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-16" data-toggle="collapse"><i class="fa fa-file-code-o title appetizer" aria-hidden="true"></i> Examples <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-16"><ul>
  <li><a href="//flink-china.org/doc/blink/examples/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/examples.html">DataStream Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/examples.html">DataSet Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/stream_sql_quickstart.html">Stream SQL Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/batch_sql_quickstart.html">Batch SQL Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/scala_shell_quickstart.html">Scala Shell Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/zeppelin_quickstart.html">Flink on Zeppelin Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/examples.html">Flink-Hive Examples</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-25" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Project Setup <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-25"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/java_api_quickstart.html">Project Template for Java</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/scala_api_quickstart.html">Project Template for Scala</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/dependencies.html">Configuring Dependencies, Connectors, Libraries</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/scala_shell.html">Scala Shell</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-34" data-toggle="collapse"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-34"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-35" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-35"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-39" data-toggle="collapse">Streaming (DataStream API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-39"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/datastream_api.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-40" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-40"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/event_timestamp_extractors.html">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-44" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-44"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/stream/state/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/state.html">Working with State</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/broadcast_state.html">The Broadcast State Pattern</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/checkpointing.html">Checkpointing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/queryable_state.html">Queryable State</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/state_backends.html">State Backends</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/custom_serialization.html">Custom Serialization</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-52" data-toggle="collapse">Operators <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-52"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/stream/operators/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/windows.html">Windows</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/process_function.html">Process Function</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/asyncio.html">Async I/O</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-57" data-toggle="collapse">Connectors <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-57"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/connectors/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/kafka.html">Kafka</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/kinesis.html">Kinesis</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/side_output.html">Side Outputs</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/testing.html">Testing</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/experimental.html">Experimental Features</a></li>
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-73" data-toggle="collapse">Batch (DataSet API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-73"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/batch/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/iterations.html">Iterations</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-84" data-toggle="collapse">Table API & SQL <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-84"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/table/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/common.html">Concepts & Common API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/hive_compatibility.html">Hive Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-87" data-toggle="collapse">Streaming Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-87"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/table/streaming/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/dynamic_tables.html">Dynamic Tables</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/time_attributes.html">Time Attributes</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/joins.html">Joins in Continuous Queries</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/temporal_tables.html">Temporal Tables</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/match_recognize.html">Detecting Patterns</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/tableApi.html">Table API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sql.html">SQL</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/supported_ddl.html">SQL Sources & Sinks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sourceSinks.html">Table Sources & Sinks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/udfs.html">User-defined Functions</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sqlClient.html">SQL Client</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/resource.html">SQL Resource</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/catalog.html">Catalog</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming_optimization.html">Streaming Aggregation Optimization</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/multiple_tablesink_optimization.html">Multiple TableSink Optimization</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-106" data-toggle="collapse">Data Types & Serialization <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-106"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/types_serialization.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/custom_serializers.html">Custom Serializers</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-109" data-toggle="collapse">Managing Execution <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/execution_configuration.html">Execution Configuration</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/packaging.html">Program Packaging</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/parallel.html">Parallel Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/execution_plans.html">Execution Plans</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/restart_strategies.html">Restart Strategies</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-116" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-116"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-118" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-118"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/libs/gelly/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-126" data-toggle="collapse">Machine Learning <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-126"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/libs/ml/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/quickstart.html">Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/contribution_guide.html">How to Contribute</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/cross_validation.html">Cross Validation</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/distance_metrics.html">Distance Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/knn.html">k-Nearest Neighbors Join</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/min_max_scaler.html">MinMax Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/multiple_linear_regression.html">Multiple Linear Regression</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/polynomial_features.html">Polynomial Features</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/sos.html">Stochastic Outlier Selection</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/standard_scaler.html">Standard Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/svm.html">SVM using CoCoA</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/best_practices.html">Best Practices</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/migration.html">API Migration Guides</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-145" data-toggle="collapse" class="active"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment & Operations</a><div class="collapse in" id="collapse-145"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-146" data-toggle="collapse" class="active">Clusters & Deployment</a><div class="collapse in" id="collapse-146"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/yarn_setup.html" class="active">YARN</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/mesos.html">Mesos</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/kubernetes.html">Kubernetes</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/docker.html">Docker</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/aws.html">AWS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/mapr_setup.html">MapR</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/hadoop.html">Hadoop Integration</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-157" data-toggle="collapse">High Availability (HA) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-157"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/ha/jobmanager_high_availability.html">JobManager High Availability (HA)</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/ha/jobmanager_failover.html">JobManager Failover</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-161" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-161"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/checkpoints.html">Checkpoints</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/savepoints.html">Savepoints</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/state_backends.html">State Backends</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/ops/config.html">Configuration</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/production_ready.html">Production Readiness Checklist</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/cli.html">CLI</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/security-kerberos.html">Kerberos</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/zeppelin.html">Flink on Zeppelin</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/filesystems.html">File Systems</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-176" data-toggle="collapse"><i class="fa fa-bug title maindish" aria-hidden="true"></i> Debugging & Monitoring <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-176"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/logging.html">Logging</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/historyserver.html">History Server</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_event_time.html">Debugging Windows & Event Time</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_classloading.html">Debugging Classloading</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/application_profiling.html">Application Profiling</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_job_resources.html">Debugging Job Resources</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-188" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-188"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/components.html">Component Stack</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/task_lifecycle.html">Task Lifecycle</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/taskmanager_resource.html">TaskManager Resource</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/filesystems.html">File Systems</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//flink-china.org/doc/blink/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">
          

          





  
  
    
    
      
    
  

  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment & Operations</li>
  

  
  
    <li>Clusters & Deployment</li>
  

  
  
    <li class="active">YARN</li>
  

</ol>

<h1>YARN Setup</h1>




<ul id="markdown-toc">
  <li><a href="#quickstart" id="markdown-toc-quickstart">Quickstart</a>    <ul>
      <li><a href="#run-a-single-flink-job-on-yarn-per-job-mode" id="markdown-toc-run-a-single-flink-job-on-yarn-per-job-mode">Run a single Flink job on YARN (per-job mode)</a></li>
      <li><a href="#run-flink-jobs-on-yarn-session-mode" id="markdown-toc-run-flink-jobs-on-yarn-session-mode">Run Flink jobs on YARN (session mode)</a></li>
    </ul>
  </li>
  <li><a href="#flink-yarn-session" id="markdown-toc-flink-yarn-session">Flink YARN Session</a>    <ul>
      <li><a href="#start-flink-session" id="markdown-toc-start-flink-session">Start Flink Session</a></li>
      <li><a href="#submit-job-to-an-existing-session" id="markdown-toc-submit-job-to-an-existing-session">Submit Job to an existing Session</a></li>
    </ul>
  </li>
  <li><a href="#run-a-single-flink-job-on-yarn" id="markdown-toc-run-a-single-flink-job-on-yarn">Run a single Flink job on YARN</a>    <ul>
      <li><a href="#user-jars--classpath" id="markdown-toc-user-jars--classpath">User jars &amp; Classpath</a></li>
    </ul>
  </li>
  <li><a href="#recovery-behavior-of-flink-on-yarn" id="markdown-toc-recovery-behavior-of-flink-on-yarn">Recovery behavior of Flink on YARN</a></li>
  <li><a href="#debugging-a-failed-yarn-session" id="markdown-toc-debugging-a-failed-yarn-session">Debugging a failed YARN session</a>    <ul>
      <li><a href="#log-files" id="markdown-toc-log-files">Log Files</a></li>
      <li><a href="#yarn-client-console--web-interfaces" id="markdown-toc-yarn-client-console--web-interfaces">YARN Client console &amp; Web interfaces</a></li>
    </ul>
  </li>
  <li><a href="#build-yarn-client-for-a-specific-hadoop-version" id="markdown-toc-build-yarn-client-for-a-specific-hadoop-version">Build YARN client for a specific Hadoop version</a></li>
  <li><a href="#running-flink-on-yarn-behind-firewalls" id="markdown-toc-running-flink-on-yarn-behind-firewalls">Running Flink on YARN behind Firewalls</a></li>
  <li><a href="#background--internals" id="markdown-toc-background--internals">Background / Internals</a></li>
  <li><a href="#yarn-shuffle-service" id="markdown-toc-yarn-shuffle-service">YARN shuffle service</a>    <ul>
      <li><a href="#run-batch-jobs-with-yarn-shuffle-service" id="markdown-toc-run-batch-jobs-with-yarn-shuffle-service">Run batch jobs with YARN shuffle service</a></li>
      <li><a href="#configure-the-yarn-shuffle-service" id="markdown-toc-configure-the-yarn-shuffle-service">Configure the YARN shuffle service</a></li>
    </ul>
  </li>
</ul>

<h2 id="quickstart">Quickstart</h2>

<p>Please refer to the hadoop document to install hadoop cluster. After the Hadoop cluster has installed, you need to configure the environment variables.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">export </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span>/etc/hadoop/conf/</code></pre></figure>

<p>On Linux systems, you can add such line to .bashrc file under $HOME directory to make it permanently for all future bash sessions.</p>

<h3 id="run-a-single-flink-job-on-yarn-per-job-mode">Run a single Flink job on YARN (per-job mode)</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># get the hadoop2 package from the Flink download page at</span>
<span class="c"># http://flink.apache.org/downloads.html</span>
curl <span class="nt">-O</span> &lt;flink_hadoop2_download_url&gt;
<span class="nb">tar </span>xvzf flink-1.5.1-bin-hadoop2.tgz
<span class="nb">cd </span>flink-1.5.1/
./bin/flink run <span class="nt">-m</span> yarn-cluster <span class="nt">-yn</span> 4 <span class="nt">-yjm</span> 1024 <span class="nt">-ytm</span> 4096 ./examples/batch/WordCount.jar</code></pre></figure>

<p>You can see the job you just submitted on Yarn’s Resource Manager WebUI.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn_quickstart_perjob_rm.png" class="img-responsive" /></p>

<p>Click ‘ApplicationMaster’, and you can see flink’s dashboard.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn_quickstart_perjob_flink_dashboard.png" class="img-responsive" /></p>

<h3 id="run-flink-jobs-on-yarn-session-mode">Run Flink jobs on YARN (session mode)</h3>
<h4 id="create-yarn-session">Create yarn session</h4>

<p>Start a YARN session with 4 Task Managers (each with 4 GB of Heapspace):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># get the hadoop2 package from the Flink download page at</span>
<span class="c"># http://flink.apache.org/downloads.html</span>
curl <span class="nt">-O</span> &lt;flink_hadoop2_download_url&gt;
<span class="nb">tar </span>xvzf flink-1.5.1-bin-hadoop2.tgz
<span class="nb">cd </span>flink-1.5.1/
./bin/yarn-session.sh <span class="nt">-n</span> 4 <span class="nt">-jm</span> 1024 <span class="nt">-tm</span> 4096</code></pre></figure>

<p>Specify the <code class="highlighter-rouge">-s</code> flag for the number of processing slots per Task Manager. We recommend to set the number of slots to the number of processors per machine.</p>

<p>If you do not want to keep the Flink YARN client running all the time, it’s also possible to start a detached YARN session. The parameter for that is called -d or –detached.</p>

<p>You can see the session you just submitted on Yarn’s Resource Manager WebUI.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn_quickstart_session_rm.png" class="img-responsive" /></p>

<p>Click ‘ApplicationMaster’, and you can see flink’s dashboard without any job submited.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn_quickstart_session_flink_dashboard.png" class="img-responsive" /></p>

<h4 id="submit-job-to-session">Submit job to session</h4>
<p>Once the session has been started, you can submit jobs to the cluster using the <code class="highlighter-rouge">./bin/flink</code> tool.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/flink run ./examples/streaming/WordCount.jar</code></pre></figure>

<p>Now you can see the flink job you just submited on the dashboard.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn_quickstart_session_flink_dashboard_wordcount.png" class="img-responsive" /></p>

<p>If the resources are sufficient, you can continue to submit jobs to this session.</p>

<h4 id="stop-session">Stop session</h4>
<p>To stop the session, you can attach to it by entering ‘stop’ into the client.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/yarn-session.sh <span class="nt">-id</span> application_1543205128210_0016</code></pre></figure>

<p>Or you can use <code class="highlighter-rouge">yarn application -kill $applicationId</code> to kill it.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">yarn application <span class="nt">-kill</span> application_1543205128210_0016</code></pre></figure>

<h2 id="flink-yarn-session">Flink YARN Session</h2>

<p>Apache <a href="http://hadoop.apache.org/">Hadoop YARN</a> is a cluster resource management framework. It allows to run various distributed applications on top of a cluster. Flink runs on YARN next to other applications. Users do not have to setup or install anything if there is already a YARN setup.</p>

<p><strong>Requirements</strong></p>

<ul>
  <li>at least Apache Hadoop 2.2</li>
  <li>HDFS (Hadoop Distributed File System) (or another distributed file system supported by Hadoop)</li>
</ul>

<p>If you have troubles using the Flink YARN client, have a look in the <a href="http://flink.apache.org/faq.html#yarn-deployment">FAQ section</a>.</p>

<h3 id="start-flink-session">Start Flink Session</h3>

<p>Follow these instructions to learn how to launch a Flink Session within your YARN cluster.</p>

<p>A session will start all required Flink services (JobManager and TaskManagers) so that you can submit programs to the cluster. Note that you can run multiple programs per session.</p>

<h4 id="download-flink">Download Flink</h4>

<p>Download a Flink package for Hadoop &gt;= 2 from the <a href="http://flink.apache.org/downloads.html">download page</a>. It contains the required files.</p>

<p>Extract the package using:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">tar </span>xvzf flink-1.5.1-bin-hadoop2.tgz
<span class="nb">cd </span>flink-1.5.1/</code></pre></figure>

<h4 id="start-a-session">Start a Session</h4>

<p>Use the following command to start a session</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/yarn-session.sh</code></pre></figure>

<p>This command will show you the following overview:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">Usage:
   Required
     <span class="nt">-n</span>,--container &lt;arg&gt;   Number of YARN container to allocate <span class="o">(=</span>Number of Task Managers<span class="o">)</span>
   Optional
     <span class="nt">-D</span> &lt;arg&gt;                        Dynamic properties
     <span class="nt">-d</span>,--detached                   Start detached
     <span class="nt">-jm</span>,--jobManagerMemory &lt;arg&gt;    Memory <span class="k">for </span>JobManager Container <span class="o">[</span><span class="k">in </span>MB]
     <span class="nt">-nm</span>,--name                      Set a custom name <span class="k">for </span>the application on YARN
     <span class="nt">-q</span>,--query                      Display available YARN resources <span class="o">(</span>memory, cores<span class="o">)</span>
     <span class="nt">-qu</span>,--queue &lt;arg&gt;               Specify YARN queue.
     <span class="nt">-s</span>,--slots &lt;arg&gt;                Number of slots per TaskManager
     <span class="nt">-sl</span>,--sharedLib &lt;path&gt;          Upload a copy of Flink lib beforehand and specify the path
                                     to use public visibility feature of YARN NM localizing resources
     <span class="nt">-t</span>,--ship &lt;arg&gt;                 Ship jars, files and directory <span class="k">for </span>cluster <span class="o">(</span>t <span class="k">for </span>transfer<span class="o">)</span>,
                                     Use <span class="s1">','</span> to separate multiple files.
                                     The files could be <span class="k">in </span><span class="nb">local </span>file system or distributed file system.
                                     Use URI schema to specify which file system the jar belongs.
                                     If schema is missing, would try to get the files <span class="k">in </span><span class="nb">local </span>file system.
                                     <span class="o">(</span>eg: <span class="nt">-t</span> file:///tmp/dict,hdfs:///<span class="nv">$namenode_address</span>/tmp/dependency2.jar<span class="o">)</span>
     <span class="nt">-ta</span>,--shipArchives &lt;arg&gt;        Ship archives <span class="k">for </span>cluster <span class="o">(</span>t <span class="k">for </span>transfer<span class="o">)</span>,
                                     Use <span class="s1">','</span> to separate multiple files.
                                     The archives could be <span class="k">in </span><span class="nb">local </span>file system or distributed file system.
                                     Use URI schema to specify which file system the file belongs.
                                     If schema is missing, would try to get the archives <span class="k">in </span><span class="nb">local </span>file system. 
                                     Use <span class="s1">'#'</span> after the file path to specify a new name <span class="k">in </span>workdir.
                                     <span class="o">(</span>eg: <span class="nt">-ta</span> file:///tmp/a.tar.gz#dict1,hdfs:///<span class="nv">$namenode_address</span>/tmp/b.tar.gz<span class="o">)</span>
     <span class="nt">-tm</span>,--taskManagerMemory &lt;arg&gt;   Memory per TaskManager Container <span class="o">[</span><span class="k">in </span>MB]
     <span class="nt">-z</span>,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths <span class="k">for </span>HA mode</code></pre></figure>

<p>Please note that the Client requires the <code class="highlighter-rouge">YARN_CONF_DIR</code> or <code class="highlighter-rouge">HADOOP_CONF_DIR</code> environment variable to be set to read the YARN and HDFS configuration.</p>

<p><strong>Example:</strong> Issue the following command to allocate 10 Task Managers, with 8 GB of memory and 32 processing slots each:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/yarn-session.sh <span class="nt">-n</span> 10 <span class="nt">-tm</span> 8192 <span class="nt">-s</span> 32</code></pre></figure>

<p>The system will use the configuration in <code class="highlighter-rouge">conf/flink-conf.yaml</code>. Please follow our <a href="//flink-china.org/doc/blink/ops/config.html">configuration guide</a> if you want to change something.</p>

<p>Flink on YARN will overwrite the following configuration parameters <code class="highlighter-rouge">jobmanager.rpc.address</code> (because the JobManager is always allocated at different machines), <code class="highlighter-rouge">taskmanager.tmp.dirs</code> (we are using the tmp directories given by YARN) and <code class="highlighter-rouge">parallelism.default</code> if the number of slots has been specified.</p>

<p>If you don’t want to change the configuration file to set configuration parameters, there is the option to pass dynamic properties via the <code class="highlighter-rouge">-D</code> flag. So you can pass parameters this way: <code class="highlighter-rouge">-Dfs.overwrite-files=true -Dtaskmanager.network.memory.min=536346624</code>.</p>

<p>The example invocation starts 11 containers (even though only 10 containers were requested), since there is one additional container for the ApplicationMaster and Job Manager.</p>

<p>Once Flink is deployed in your YARN cluster, it will show you the connection details of the Job Manager.</p>

<p>Stop the YARN session by stopping the unix process (using CTRL+C) or by entering ‘stop’ into the client.</p>

<p>Flink on YARN will only start all requested containers if enough resources are available on the cluster. Most YARN schedulers account for the requested memory of the containers,
some account also for the number of vcores. By default, the number of vcores is equal to the processing slots (<code class="highlighter-rouge">-s</code>) argument. The <code class="highlighter-rouge">taskmanager.cpu.core</code> allows overwriting the
number of vcores with a custom value.</p>

<h4 id="detached-yarn-session">Detached YARN Session</h4>

<p>If you do not want to keep the Flink YARN client running all the time, it’s also possible to start a <em>detached</em> YARN session.
The parameter for that is called <code class="highlighter-rouge">-d</code> or <code class="highlighter-rouge">--detached</code>.</p>

<p>In that case, the Flink YARN client will only submit Flink to the cluster and then close itself.
Note that in this case it’s not possible to stop the YARN session using Flink.</p>

<p>Use the YARN utilities (<code class="highlighter-rouge">yarn application -kill &lt;appId&gt;</code>) or attach to the session to stop the YARN session.</p>

<h4 id="attach-to-an-existing-session">Attach to an existing Session</h4>

<p>Use the following command to start a session</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/yarn-session.sh</code></pre></figure>

<p>This command will show you the following overview:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">Usage:
   Required
     <span class="nt">-id</span>,--applicationId &lt;yarnAppId&gt; YARN application Id</code></pre></figure>

<p>As already mentioned, <code class="highlighter-rouge">YARN_CONF_DIR</code> or <code class="highlighter-rouge">HADOOP_CONF_DIR</code> environment variable must be set to read the YARN and HDFS configuration.</p>

<p><strong>Example:</strong> Issue the following command to attach to running Flink YARN session <code class="highlighter-rouge">application_1463870264508_0029</code>:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/yarn-session.sh <span class="nt">-id</span> application_1463870264508_0029</code></pre></figure>

<p>Attaching to a running session uses YARN ResourceManager to determine Job Manager RPC port.</p>

<p>Stop the YARN session by stopping the unix process (using CTRL+C) or by entering ‘stop’ into the client.</p>

<h3 id="submit-job-to-an-existing-session">Submit Job to an existing Session</h3>

<p>Use the following command to submit a Flink program to the YARN cluster:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/flink</code></pre></figure>

<p>Please refer to the documentation of the <a href="//flink-china.org/doc/blink/ops/cli.html">command-line client</a>.</p>

<p>The command will show you a help menu like this:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="o">[</span>...]
Action <span class="s2">"run"</span> compiles and runs a program.

  Syntax: run <span class="o">[</span>OPTIONS] &lt;jar-file&gt; &lt;arguments&gt;
  <span class="s2">"run"</span> action arguments:
     <span class="nt">-c</span>,--class &lt;classname&gt;           Class with the program entry point <span class="o">(</span><span class="s2">"main"</span>
                                      method or <span class="s2">"getPlan()"</span> method. Only needed
                                      <span class="k">if </span>the JAR file does not specify the class
                                      <span class="k">in </span>its manifest.
     <span class="nt">-m</span>,--jobmanager &lt;host:port&gt;      Address of the JobManager <span class="o">(</span>master<span class="o">)</span> to
                                      which to connect. Use this flag to connect
                                      to a different JobManager than the one
                                      specified <span class="k">in </span>the configuration.
     <span class="nt">-p</span>,--parallelism &lt;parallelism&gt;   The parallelism with which to run the
                                      program. Optional flag to override the
                                      default value specified <span class="k">in </span>the
                                      configuration
     <span class="nt">--files</span> &lt;files&gt;                  Attach custom files <span class="k">for </span>job. Directory
                                      could not be supported. Use <span class="s1">','</span> to
                                      separate multiple files. The files
                                      could be <span class="k">in </span><span class="nb">local </span>file system or
                                      distributed file system. Use URI
                                      schema to specify which file system
                                      the file belongs. If schema is
                                      missing, would try to get the file <span class="k">in
                                      </span><span class="nb">local </span>file system. Use <span class="s1">'#'</span> after the
                                      file path to specify retrieval key <span class="k">in
                                      </span>runtime. <span class="o">(</span>eg: <span class="nt">--file</span>
                                      file:///tmp/a.txt#file_key,hdfs:///<span class="nv">$na</span>
                                      menode_address/tmp/b.txt<span class="o">)</span>
     <span class="nt">--libjars</span> &lt;libraryJars&gt;          Attach custom library jars <span class="k">for </span>job.
                                      Directory could not be supported. Use
                                      <span class="s1">','</span> to separate multiple jars. The
                                      jars could be <span class="k">in </span><span class="nb">local </span>file system or
                                      distributed file system. Use URI
                                      schema to specify which file system
                                      the jar belongs. If schema is missing,
                                      would try to get the jars <span class="k">in </span><span class="nb">local
                                      </span>file system. <span class="o">(</span>eg: <span class="nt">--libjars</span>
                                      file:///tmp/dependency1.jar,hdfs:///
                                      <span class="nv">$namenode_address</span>/tmp/dependency2.jar<span class="o">)</span></code></pre></figure>

<p>Use the <em>run</em> action to submit a job to an existing Session. The client is able to determine the address of the JobManager. In the rare event of a problem, you can also pass the YARN applicationId using the <code class="highlighter-rouge">-yid</code> argument. The applicationId is visible in the YARN console.</p>

<p><strong>Example</strong></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">wget <span class="nt">-O</span> LICENSE-2.0.txt http://www.apache.org/licenses/LICENSE-2.0.txt
hadoop fs <span class="nt">-copyFromLocal</span> LICENSE-2.0.txt hdfs:/// ...
./bin/flink run ./examples/batch/WordCount.jar <span class="se">\</span>
        hdfs:///..../LICENSE-2.0.txt hdfs:///.../wordcount-result.txt</code></pre></figure>

<p>If there is the following error, make sure that all TaskManagers started:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">Exception <span class="k">in </span>thread <span class="s2">"main"</span> org.apache.flink.compiler.CompilerException:
    Available instances could not be determined from job manager: Connection timed out.</code></pre></figure>

<p>You can check the number of TaskManagers in the JobManager web interface. The address of this interface is printed in the YARN session console.</p>

<p>If the TaskManagers do not show up after a minute, you should investigate the issue using the log files.</p>

<h2 id="run-a-single-flink-job-on-yarn">Run a single Flink job on YARN</h2>

<p>The documentation above describes how to start a Flink session cluster within a Hadoop YARN environment. It is also possible to launch Flink within YARN only for executing a single job.</p>

<p><strong><em>Example:</em></strong></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./bin/flink run <span class="nt">-m</span> yarn-cluster <span class="nt">-yn</span> 2 ./examples/batch/WordCount.jar</code></pre></figure>

<p>The command line options of the YARN session are also available with the <code class="highlighter-rouge">./bin/flink</code> tool. They are prefixed with a <code class="highlighter-rouge">y</code> or <code class="highlighter-rouge">yarn</code> (for the long argument options).</p>

<p>Note: The client expects the <code class="highlighter-rouge">-yn</code> value to be set (number of TaskManagers) in attach mode.</p>

<p>Note: You can use a different configuration directory per job by setting the environment variable <code class="highlighter-rouge">FLINK_CONF_DIR</code>. To use this copy the <code class="highlighter-rouge">conf</code> directory from the Flink distribution and modify, for example, the logging settings on a per-job basis.</p>

<p>Note: It is possible to combine <code class="highlighter-rouge">-m yarn-cluster</code> with a detached YARN submission (<code class="highlighter-rouge">-d</code>) to “fire and forget” a Flink job to the YARN cluster. The <code class="highlighter-rouge">-yn</code> will not take effect and resource is allocated as demand. Also in this case, your application will not get any accumulator results or exceptions from the ExecutionEnvironment.execute() call!</p>

<h3 id="user-jars--classpath">User jars &amp; Classpath</h3>

<p>By default Flink will include the user jars into the system classpath when running a single job. This behavior can be controlled with the <code class="highlighter-rouge">yarn.per-job-cluster.include-user-jar</code> parameter.</p>

<p>When setting this to <code class="highlighter-rouge">DISABLED</code> Flink will include the jar in the user classpath instead.</p>

<p>The user-jars position in the class path can be controlled by setting the parameter to one of the following:</p>

<ul>
  <li><code class="highlighter-rouge">ORDER</code>: (default) Adds the jar to the system class path based on the lexicographic order.</li>
  <li><code class="highlighter-rouge">FIRST</code>: Adds the jar to the beginning of the system class path.</li>
  <li><code class="highlighter-rouge">LAST</code>: Adds the jar to the end of the system class path.</li>
</ul>

<h2 id="recovery-behavior-of-flink-on-yarn">Recovery behavior of Flink on YARN</h2>

<p>Flink’s YARN client has the following configuration parameters to control how to behave in case of container failures. These parameters can be set either from the <code class="highlighter-rouge">conf/flink-conf.yaml</code> or when starting the YARN session, using <code class="highlighter-rouge">-D</code> parameters.</p>

<ul>
  <li><code class="highlighter-rouge">yarn.reallocate-failed</code>: This parameter controls whether Flink should reallocate failed TaskManager containers. Default: true</li>
  <li><code class="highlighter-rouge">yarn.maximum-failed-containers</code>: The maximum number of failed containers the ApplicationMaster accepts until it fails the YARN session. Default: The number of initially requested TaskManagers (<code class="highlighter-rouge">-n</code>).</li>
  <li><code class="highlighter-rouge">yarn.application-attempts</code>: The number of ApplicationMaster (+ its TaskManager containers) attempts. If this value is set to 1 (default), the entire YARN session will fail when the Application master fails. Higher values specify the number of restarts of the ApplicationMaster by YARN.</li>
</ul>

<h2 id="debugging-a-failed-yarn-session">Debugging a failed YARN session</h2>

<p>There are many reasons why a Flink YARN session deployment can fail. A misconfigured Hadoop setup (HDFS permissions, YARN configuration), version incompatibilities (running Flink with vanilla Hadoop dependencies on Cloudera Hadoop) or other errors.</p>

<h3 id="log-files">Log Files</h3>

<p>In cases where the Flink YARN session fails during the deployment itself, users have to rely on the logging capabilities of Hadoop YARN. The most useful feature for that is the <a href="http://hortonworks.com/blog/simplifying-user-logs-management-and-access-in-yarn/">YARN log aggregation</a>.
To enable it, users have to set the <code class="highlighter-rouge">yarn.log-aggregation-enable</code> property to <code class="highlighter-rouge">true</code> in the <code class="highlighter-rouge">yarn-site.xml</code> file.
Once that is enabled, users can use the following command to retrieve all log files of a (failed) YARN session.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">yarn logs <span class="nt">-applicationId</span> &lt;application ID&gt;</code></pre></figure>

<p>Note that it takes a few seconds after the session has finished until the logs show up.</p>

<h3 id="yarn-client-console--web-interfaces">YARN Client console &amp; Web interfaces</h3>

<p>The Flink YARN client also prints error messages in the terminal if errors occur during runtime (for example if a TaskManager stops working after some time).</p>

<p>In addition to that, there is the YARN Resource Manager web interface (by default on port 8088). The port of the Resource Manager web interface is determined by the <code class="highlighter-rouge">yarn.resourcemanager.webapp.address</code> configuration value.</p>

<p>It allows to access log files for running YARN applications and shows diagnostics for failed apps.</p>

<h2 id="build-yarn-client-for-a-specific-hadoop-version">Build YARN client for a specific Hadoop version</h2>

<p>Users using Hadoop distributions from companies like Hortonworks, Cloudera or MapR might have to build Flink against their specific versions of Hadoop (HDFS) and YARN. Please read the <a href="//flink-china.org/doc/blink/start/building.html">build instructions</a> for more details.</p>

<h2 id="running-flink-on-yarn-behind-firewalls">Running Flink on YARN behind Firewalls</h2>

<p>Some YARN clusters use firewalls for controlling the network traffic between the cluster and the rest of the network.
In those setups, Flink jobs can only be submitted to a YARN session from within the cluster’s network (behind the firewall).
If this is not feasible for production use, Flink allows to configure a port range for all relevant services. With these
ranges configured, users can also submit jobs to Flink crossing the firewall.</p>

<p>Currently, two services are needed to submit a job:</p>

<ul>
  <li>The JobManager (ApplicationMaster in YARN)</li>
  <li>The BlobServer running within the JobManager.</li>
</ul>

<p>When submitting a job to Flink, the BlobServer will distribute the jars with the user code to all worker nodes (TaskManagers).
The JobManager receives the job itself and triggers the execution.</p>

<p>The two configuration parameters for specifying the ports are the following:</p>

<ul>
  <li><code class="highlighter-rouge">yarn.application-master.port</code></li>
  <li><code class="highlighter-rouge">blob.server.port</code></li>
</ul>

<p>These two configuration options accept single ports (for example: “50010”), ranges (“50000-50025”), or a combination of
both (“50010,50011,50020-50025,50050-50075”).</p>

<p>(Hadoop is using a similar mechanism, there the configuration parameter is called <code class="highlighter-rouge">yarn.app.mapreduce.am.job.client.port-range</code>.)</p>

<h2 id="background--internals">Background / Internals</h2>

<p>This section briefly describes how Flink and YARN interact.</p>

<p><img src="//flink-china.org/doc/blink/fig/FlinkOnYarn.svg" class="img-responsive" /></p>

<p>There are two execution modes to start a Flink application:</p>
<ul>
  <li>session mode: All required Flink services (JobManager and TaskManagers) will be started at first even though there is no job submitted, and keep running until the flink cluster has stopped, so that you can submit jobs to the cluster whenever you want. This mode can effectively enhance the execution efficiency for short-term jobs.</li>
  <li>per-job mode: Flink services will be started based on a specific job, and will be stopped after the job finished. In this mode, job will use exactly as many resources as needed, and will release them right after the tasks finished, it’s better for resource isolation between jobs and resource efficiency of the cluster.</li>
</ul>

<p>The YARN client needs to access the Hadoop configuration to connect to the YARN resource manager and to HDFS. It determines the Hadoop configuration using the following strategy:</p>

<ul>
  <li>Test if <code class="highlighter-rouge">YARN_CONF_DIR</code>, <code class="highlighter-rouge">HADOOP_CONF_DIR</code> or <code class="highlighter-rouge">HADOOP_CONF_PATH</code> are set (in that order). If one of these variables are set, they are used to read the configuration.</li>
  <li>If the above strategy fails (this should not be the case in a correct YARN setup), the client is using the <code class="highlighter-rouge">HADOOP_HOME</code> environment variable. If it is set, the client tries to access <code class="highlighter-rouge">$HADOOP_HOME/etc/hadoop</code> (Hadoop 2) and <code class="highlighter-rouge">$HADOOP_HOME/conf</code> (Hadoop 1).</li>
</ul>

<p>When starting a new Flink application, the client first checks if the requested resources (containers and memory) are available. After that, it uploads required jars (including Flink framework jar and user jars), job graph (only in per-job mode) and the configuration to HDFS as distributed cache of this application (step 1).</p>

<p>The next step of the client is to request (step 2) a YARN container to start the <em>ApplicationMaster</em> (step 3). Since the client registered the configuration and jar-file as a resource for the container, the NodeManager of YARN running on that particular machine will take care of preparing the container (e.g. downloading the files). Once that has finished, the <em>ApplicationMaster</em> (AM) is started.</p>

<p>The <em>JobManager</em> and AM are running in the same container. Once they successfully started, the AM knows the address of the JobManager (its own host). It is generating a new Flink configuration file for the TaskManagers (so that they can connect to the JobManager). The file is also uploaded to HDFS. Additionally, the <em>AM</em> container is also serving Flink’s web interface. All ports the YARN code is allocating are <em>ephemeral ports</em>. This allows users to execute multiple Flink YARN applications in parallel.</p>

<p>After that, the AM starts allocating the containers for Flink’s TaskManagers, which will download the required jars and the modified configuration from the HDFS. In session mode, TaskManagers are allocated based on configuration which defines the resource and number of TaskManagers, once these steps are completed, Flink is set up and ready to accept Jobs. In per-job mode, TaskManagers are allocated based on the job graph retrieved from distributed cache, Flink ResourceManager can internally combine several tiny slots with the same resource profile in one container to enhance scheduling efficiency.</p>

<h2 id="yarn-shuffle-service">YARN shuffle service</h2>
<h3 id="run-batch-jobs-with-yarn-shuffle-service">Run batch jobs with YARN shuffle service</h3>

<p>YARN shuffle service provides an external endpoint for serving the intermediate data between tasks. It serves as an alternative to the built-in endpoint embedded in the TaskManager. With YARN shuffle service the map-side TaskManagers do not need to wait till the reduce-side tasks finish reading to shutdown, therefore the maximum resources required can be reduced.</p>

<p>YARN shuffle service acts as a plugin of the NodeManager and you first need to start it on each NodeManager in your YARN cluster:</p>

<ol>
  <li>Locate the shuffle service jar. If you build Flink from source, the shuffle service jar is located at <code class="highlighter-rouge">$FLINK_SOURCE/build-target/opt/yarn-shuffle/flink-shuffle-service-&lt;version&gt;.jar</code>. If your are using pre-packaged distribution, The shuffle service jar is located at <code class="highlighter-rouge">$FLINK_DIST_HOME/opt/yarn-shuffle//flink-shuffle-service-&lt;version&gt;.jar</code>.</li>
  <li>Add this jar to the CLASSPATH of all the NodeManagers in your YARN cluster.</li>
  <li>Add the following configuration in the <code class="highlighter-rouge">yarn-site.xml</code>:
    <pre><code class="language-$xslt"> &lt;property&gt;
   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;!-- Add yarn_shuffle_service_for_flink to the end of the list  --&gt;
   &lt;value&gt;..., yarn_shuffle_service_for_flink&lt;/value&gt;
 &lt;/property&gt;
    
 &lt;property&gt;
   &lt;name&gt;yarn.nodemanager.aux-services.yarn_shuffle_service_for_flink.class&lt;/name&gt;
   &lt;value&gt;org.apache.flink.network.yarn.YarnShuffleService&lt;/value&gt;
 &lt;/property&gt;
</code></pre>
  </li>
  <li>By default shuffle service will use up to 300MB of direct memory and 64MB of heap memory. Increase the configured memory of the NodeManagers if needed.</li>
  <li>Restart all the NodeManagers in your YARN cluster.</li>
</ol>

<p>After the shuffle service has started, you can create batch jobs with the Table API to use the shuffle service. Batch jobs can be declared with the Table API by setting</p>

<pre><code class="language-$xslt">sql.exec.data-exchange-mode.all-batch: true
</code></pre>

<p>By default, the intermediate data of the batch jobs are served by the embedded endpoint in the TaskManager. To change the endpoint to the YARN shuffle service, you need to set the following configuration:</p>

<pre><code class="language-$xslt">task.blocking.shuffle.type: YARN
</code></pre>

<h3 id="configure-the-yarn-shuffle-service">Configure the YARN shuffle service</h3>

<div class="alert alert-warning">
  <strong>Note:</strong> The shuffle service acts as a plugin in in the YARN NodeManager, so all the following configurations should be set in the <code>yarn-site.xml</code>.
</div>

<p>The basic architecture of the shuffle service is illustrated as follows. The map-side tasks first write data to disks, then the shuffle service reads  data out and sends them to the reduce-side tasks.</p>

<p><img src="//flink-china.org/doc/blink/fig/yarn-shuffle-service.png" class="img-responsive" style="width: 80%" /></p>

<h4 id="configure-the-root-directories">Configure the root directories</h4>
<p>YARN shuffle service supports using multiple directories to store the intermediate data on a single machine. The default root directories are the NodeManager local directories. You can change the default directories by configuring <code class="highlighter-rouge">flink.shuffle-service.local-dirs</code>, but it is not recommended since other directories cannot be cleared by YARN when the applications stop.</p>

<p>YARN shuffle service maintains a group of threads to read data from each directory. Suitable number of read threads may differ for directories with different disk types, therefore, YARN shuffle service allows user to specify the disk types of each directory and configure different thread number for each disk type.</p>

<p>By default YARN shuffle service treats all the directories to be on HDD, and the default number of threads is configured by <code class="highlighter-rouge">flink.shuffle-service.default-io-thread-number-per-disk</code>. To change the default behavior, you can configure the directory disk types with <code class="highlighter-rouge">flink.shuffle-service.local-dirs</code> and configure the thread numbers for each disk type by <code class="highlighter-rouge">flink.shuffle-service.io-thread-number-for-disk-type</code>.</p>

<p>For example, suppose the NodeManager local directories are <code class="highlighter-rouge">/disk/1/nm-local,/disk/2/nm-local</code> and <code class="highlighter-rouge">/disk/1</code> locates on SSD, if you want the YARN shuffle service to be aware of the disk types, you need to</p>

<ol>
  <li>Configure <code class="highlighter-rouge">flink.shuffle-service.local-dirs</code> to <code class="highlighter-rouge">[SSD]/disk/1/nm-local,/disk/2/nm-local</code>.</li>
  <li>Configure <code class="highlighter-rouge">flink.shuffle-service.io-thread-number-for-disk-type</code> to <code class="highlighter-rouge">SSD: 20</code> to start 20 IO thread for each root directory on SSD.</li>
</ol>

<p>When the YARN shuffle service is aware of the disk types, you can also configure to use directories on specific type of disks, as described in <a href="//flink-china.org/doc/blink/ops/config.html#configure-the-disk-type-preferred">Configure the jobs using external shuffle services</a>.</p>

<h4 id="configure-the--memory">Configure the  memory</h4>
<p>The total direct and heap memory consumed by the YARN shuffle service is configured by <code class="highlighter-rouge">flink.shuffle-service.direct-memory-limit-in-mb</code> and <code class="highlighter-rouge">flink.shuffle-service.heap-memory-limit-in-mb</code>. The direct and heap memory of the NodeManager should also be increased accordingly.</p>

<h4 id="ttl-for-cleaning-data">TTL for cleaning data</h4>

<p>YARN shuffle service cleans the intermediate data in two ways:</p>

<ol>
  <li>When one application finishes, YARN will clear its local directory and the intermediate data under the local directory will be cleared meanwhile.</li>
  <li>Every intermediate data directory also has a TTL, once the interval since the intermediate data directory get inactive exceeds the TTL, the intermediate data directory will be cleared. The TTL is useful for jobs running on a long live session whose corresponding application will not finish before the session stops.</li>
</ol>

<p>YARN shuffle service classify the intermediate data directories into four types and each type of directories can be configured separately:</p>

<ul>
  <li>Consumed: All the reduce side tasks have read the intermediate data.</li>
  <li>Partial-consumed: Parts of the reduce side tasks have read the intermediate data.</li>
  <li>Unconsumed: None of the reduce side tasks have read the intermediate data.</li>
  <li>Unfinished: The intermediate data is still being written.</li>
</ul>

<h4 id="full-references">Full references</h4>
<table class="table table-bordered">
    <thead>
        <tr>
            <th class="text-left" style="width: 20%">Key</th>
            <th class="text-left" style="width: 15%">Default</th>
            <th class="text-left" style="width: 65%">Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><h5>flink.shuffle-service.consumed-partition-ttl-in-seconds</h5></td>
            <td style="word-wrap: break-word;">3600</td>
            <td>The time interval to delete the fully consumed shuffle data directories since they become inactive.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.default-io-thread-number-per-disk</h5></td>
            <td style="word-wrap: break-word;">4</td>
            <td>The thread number for the default HDD disk type.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.direct-memory-limit-in-mb</h5></td>
            <td style="word-wrap: break-word;">300</td>
            <td>The direct memory consumed by the yarn shuffle service.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.disk-scan-interval-in-ms</h5></td>
            <td style="word-wrap: break-word;">15000</td>
            <td></td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.heap-memory-limit-in-mb</h5></td>
            <td style="word-wrap: break-word;">64</td>
            <td>The heap memory consumed by the yarn shuffle service</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.internal.local-result-partition-resolver-class</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td></td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.io-thread-number-for-disk-type</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>The list of disk types and thread numbers. Each disk type and the corresponding thread number is configured by TYPE_1: THREAD_1, TYPE_2: THREAD_2, ...</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.local-dirs</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>The list of local directories separated by comma. Each directory can be configured with the disk type ([TYPE] directory,...) or without the disk type (directory, ...). If not configured, the NodeManager local directories will be used and each directory will be treated as on HDD.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.memory-size-per-buffer-in-bytes</h5></td>
            <td style="word-wrap: break-word;">32768</td>
            <td></td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.netty-memory-in-mb</h5></td>
            <td style="word-wrap: break-word;">0</td>
            <td>The preferred number of netty IO threads. If it's positive, the netty memory size will be min(configured value, 4M * flink.shuffle-service.server-thread-number), otherwise the netty memory size will be min(1/2 * flink.shuffle-service.direct-memory-limit-in-mb, 4M * flink.shuffle-service.server-thread-number).</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.partial-consumed-partition-ttl-in-seconds</h5></td>
            <td style="word-wrap: break-word;">43200</td>
            <td>The time interval to delete the partially consumed shuffle data directories since they become inactive.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.port</h5></td>
            <td style="word-wrap: break-word;">14572</td>
            <td>The port of the shuffle service.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.server-thread-number</h5></td>
            <td style="word-wrap: break-word;">0</td>
            <td>The number of netty IO threads. If it's not positive, the thread number is equal to the overall IO thread number</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.subpartition-request-comparator-class</h5></td>
            <td style="word-wrap: break-word;">"org.<wbr />apache.<wbr />flink.<wbr />runtime.<wbr />io.<wbr />network.<wbr />partition.<wbr />external.<wbr />CreditBasedSubpartitionViewComparator"</td>
            <td>The comparator to decide the next subpartition to serve.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.unconsumed-partition-ttl-in-seconds</h5></td>
            <td style="word-wrap: break-word;">43200</td>
            <td>TThe time interval to delete the unconsumed shuffle data directories since they are ready to consume.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.unfinished-partition-ttl-in-seconds</h5></td>
            <td style="word-wrap: break-word;">3600</td>
            <td>The time interval to delete the writing shuffle data directories since the last writing.</td>
        </tr>
        <tr>
            <td><h5>flink.shuffle-service.wait-credit-delay-in-ms</h5></td>
            <td style="word-wrap: break-word;">0</td>
            <td></td>
        </tr>
    </tbody>
</table>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//flink-china.org/doc/blink/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//flink-china.org/doc/blink/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
