<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.5.1 Documentation: Concepts & Common API</title>
    <link rel="shortcut icon" href="//flink-china.org/doc/blink/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="//flink-china.org/doc/blink/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/flink.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/syntax.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/css/codetabs.css">
    <link rel="stylesheet" href="//flink-china.org/doc/blink/page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    

    <!-- Main content. -->
    <div class="container">
      
      <div class="row">
        <div class="col-lg-3" id="sidenavcol">
          







  
    
    
    
      
    
  

  
    
    
    
      
    
  

  
    
    
    
      













<div class="sidenav-logo">
  <p><a href="//flink-china.org/doc/blink"><img class="bottom" alt="Apache Flink" src="//flink-china.org/doc/blink/page/img/navbar-brand-logo.jpg"></a> v1.5.1</p>
</div>
<ul id="sidenav">

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li>
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/concepts/programming-model.html">Programming Model</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-6" data-toggle="collapse"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-6"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse">API Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-7"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/datastream_api.html">DataStream API</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-10" data-toggle="collapse">Setup Tutorials <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-10"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/local_setup.html">Local Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/tutorials/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/setup_quickstart.html"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-16" data-toggle="collapse"><i class="fa fa-file-code-o title appetizer" aria-hidden="true"></i> Examples <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-16"><ul>
  <li><a href="//flink-china.org/doc/blink/examples/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/examples.html">DataStream Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/examples.html">DataSet Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/stream_sql_quickstart.html">Stream SQL Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/batch_sql_quickstart.html">Batch SQL Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/scala_shell_quickstart.html">Scala Shell Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/zeppelin_quickstart.html">Flink on Zeppelin Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/examples.html">Flink-Hive Examples</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-25" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Project Setup <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-25"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/java_api_quickstart.html">Project Template for Java</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/quickstart/scala_api_quickstart.html">Project Template for Scala</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/dependencies.html">Configuring Dependencies, Connectors, Libraries</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/scala_shell.html">Scala Shell</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/start/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-34" data-toggle="collapse" class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</a><div class="collapse in" id="collapse-34"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-35" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-35"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-39" data-toggle="collapse">Streaming (DataStream API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-39"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/datastream_api.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-40" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-40"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/event_timestamp_extractors.html">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-44" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-44"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/stream/state/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/state.html">Working with State</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/broadcast_state.html">The Broadcast State Pattern</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/checkpointing.html">Checkpointing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/queryable_state.html">Queryable State</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/state_backends.html">State Backends</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/state/custom_serialization.html">Custom Serialization</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-52" data-toggle="collapse">Operators <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-52"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/stream/operators/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/windows.html">Windows</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/process_function.html">Process Function</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/operators/asyncio.html">Async I/O</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-57" data-toggle="collapse">Connectors <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-57"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/connectors/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/guarantees.html">Fault Tolerance Guarantees</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/kafka.html">Kafka</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/kinesis.html">Kinesis</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/side_output.html">Side Outputs</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/stream/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/testing.html">Testing</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/dev/stream/experimental.html">Experimental Features</a></li>
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-73" data-toggle="collapse">Batch (DataSet API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-73"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/batch/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/iterations.html">Iterations</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-84" data-toggle="collapse" class="active">Table API & SQL</a><div class="collapse in" id="collapse-84"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/table/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/common.html" class="active">Concepts & Common API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/hive_compatibility.html">Hive Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-87" data-toggle="collapse">Streaming Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-87"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/table/streaming/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/dynamic_tables.html">Dynamic Tables</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/time_attributes.html">Time Attributes</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/joins.html">Joins in Continuous Queries</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/temporal_tables.html">Temporal Tables</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/match_recognize.html">Detecting Patterns</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming/query_configuration.html">Query Configuration</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/tableApi.html">Table API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sql.html">SQL</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/supported_ddl.html">SQL Sources & Sinks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sourceSinks.html">Table Sources & Sinks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/udfs.html">User-defined Functions</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/sqlClient.html">SQL Client</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/resource.html">SQL Resource</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/catalog.html">Catalog</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/streaming_optimization.html">Streaming Aggregation Optimization</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/table/multiple_tablesink_optimization.html">Multiple TableSink Optimization</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-106" data-toggle="collapse">Data Types & Serialization <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-106"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/types_serialization.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/custom_serializers.html">Custom Serializers</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-109" data-toggle="collapse">Managing Execution <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-109"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/execution_configuration.html">Execution Configuration</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/packaging.html">Program Packaging</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/parallel.html">Parallel Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/execution_plans.html">Execution Plans</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/restart_strategies.html">Restart Strategies</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-116" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-116"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-118" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-118"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/libs/gelly/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/gelly/bipartite_graph.html">Bipartite Graph</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-126" data-toggle="collapse">Machine Learning <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-126"><ul>
  <li><a href="//flink-china.org/doc/blink/dev/libs/ml/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/quickstart.html">Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/contribution_guide.html">How to Contribute</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/cross_validation.html">Cross Validation</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/distance_metrics.html">Distance Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/knn.html">k-Nearest Neighbors Join</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/min_max_scaler.html">MinMax Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/multiple_linear_regression.html">Multiple Linear Regression</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/polynomial_features.html">Polynomial Features</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/sos.html">Stochastic Outlier Selection</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/standard_scaler.html">Standard Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/libs/ml/svm.html">SVM using CoCoA</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/best_practices.html">Best Practices</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/dev/migration.html">API Migration Guides</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-145" data-toggle="collapse"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Deployment & Operations <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-145"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-146" data-toggle="collapse">Clusters & Deployment <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-146"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/yarn_setup.html">YARN</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/mesos.html">Mesos</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/kubernetes.html">Kubernetes</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/docker.html">Docker</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/aws.html">AWS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/mapr_setup.html">MapR</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/deployment/hadoop.html">Hadoop Integration</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-157" data-toggle="collapse">High Availability (HA) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-157"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/ha/jobmanager_high_availability.html">JobManager High Availability (HA)</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/ha/jobmanager_failover.html">JobManager Failover</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-161" data-toggle="collapse">State & Fault Tolerance <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-161"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/checkpoints.html">Checkpoints</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/savepoints.html">Savepoints</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/state_backends.html">State Backends</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/state/large_state_tuning.html">Tuning Checkpoints and Large State</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="//flink-china.org/doc/blink/ops/config.html">Configuration</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/production_ready.html">Production Readiness Checklist</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/cli.html">CLI</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/security-kerberos.html">Kerberos</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/zeppelin.html">Flink on Zeppelin</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/filesystems.html">File Systems</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/ops/upgrading.html">Upgrading Applications and Flink Versions</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-176" data-toggle="collapse"><i class="fa fa-bug title maindish" aria-hidden="true"></i> Debugging & Monitoring <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-176"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/logging.html">Logging</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/historyserver.html">History Server</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/checkpoint_monitoring.html">Monitoring Checkpointing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/back_pressure.html">Monitoring Back Pressure</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_event_time.html">Debugging Windows & Event Time</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_classloading.html">Debugging Classloading</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/application_profiling.html">Application Profiling</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/monitoring/debugging_job_resources.html">Debugging Job Resources</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-188" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-188"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/components.html">Component Stack</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/task_lifecycle.html">Task Lifecycle</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/taskmanager_resource.html">TaskManager Resource</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="//flink-china.org/doc/blink/internals/filesystems.html">File Systems</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="//flink-china.org/doc/blink/search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.4">v1.4</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.3">v1.3</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.2">v1.2</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content" id="contentcol">
          

          





  
  
    
    
      
    
  

  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</li>
  

  
  
    <li><a href="//flink-china.org/doc/blink/dev/table/">Table API & SQL</a></li>
  

  
  
    <li class="active">Concepts & Common API</li>
  

</ol>

<h1>Concepts & Common API</h1>




<p>The Table API and SQL are integrated in a joint API. The central concept of this API is a <code class="highlighter-rouge">Table</code> which serves as input and output of queries. This document shows the common structure of programs with Table API and SQL queries, how to register a <code class="highlighter-rouge">Table</code>, how to query a <code class="highlighter-rouge">Table</code>, and how to emit a <code class="highlighter-rouge">Table</code>.</p>

<ul id="markdown-toc">
  <li><a href="#structure-of-table-api-and-sql-programs" id="markdown-toc-structure-of-table-api-and-sql-programs">Structure of Table API and SQL Programs</a></li>
  <li><a href="#create-a-tableenvironment" id="markdown-toc-create-a-tableenvironment">Create a TableEnvironment</a></li>
  <li><a href="#register-flink-tables-in-tableenvironment" id="markdown-toc-register-flink-tables-in-tableenvironment">Register Flink Tables in TableEnvironment</a>    <ul>
      <li><a href="#register-a-table" id="markdown-toc-register-a-table">Register a Table</a></li>
      <li><a href="#register-a-tablesource" id="markdown-toc-register-a-tablesource">Register a TableSource</a></li>
      <li><a href="#register-a-tablesink" id="markdown-toc-register-a-tablesink">Register a TableSink</a></li>
    </ul>
  </li>
  <li><a href="#catalogs" id="markdown-toc-catalogs">Catalogs</a></li>
  <li><a href="#query-a-table" id="markdown-toc-query-a-table">Query a Table</a>    <ul>
      <li><a href="#table-api" id="markdown-toc-table-api">Table API</a></li>
      <li><a href="#sql" id="markdown-toc-sql">SQL</a></li>
      <li><a href="#mixing-table-api-and-sql" id="markdown-toc-mixing-table-api-and-sql">Mixing Table API and SQL</a></li>
    </ul>
  </li>
  <li><a href="#emit-a-table" id="markdown-toc-emit-a-table">Emit a Table</a></li>
  <li><a href="#translate-and-execute-a-query" id="markdown-toc-translate-and-execute-a-query">Translate and Execute a Query</a></li>
  <li><a href="#integration-with-datastream-api" id="markdown-toc-integration-with-datastream-api">Integration with DataStream API</a>    <ul>
      <li><a href="#implicit-conversion-for-scala" id="markdown-toc-implicit-conversion-for-scala">Implicit Conversion for Scala</a></li>
      <li><a href="#register-a-datastream-as-table" id="markdown-toc-register-a-datastream-as-table">Register a DataStream as Table</a></li>
      <li><a href="#convert-a-datastream-into-a-table" id="markdown-toc-convert-a-datastream-into-a-table">Convert a DataStream into a Table</a></li>
      <li><a href="#convert-a-table-into-a-datastream" id="markdown-toc-convert-a-table-into-a-datastream">Convert a Table into a DataStream</a></li>
      <li><a href="#mapping-of-data-types-to-table-schema" id="markdown-toc-mapping-of-data-types-to-table-schema">Mapping of Data Types to Table Schema</a></li>
    </ul>
  </li>
  <li><a href="#query-optimization" id="markdown-toc-query-optimization">Query Optimization</a>    <ul>
      <li><a href="#reuse-subplan" id="markdown-toc-reuse-subplan">Reuse SubPlan</a></li>
      <li><a href="#explaining-a-table" id="markdown-toc-explaining-a-table">Explaining a Table</a></li>
      <li><a href="#alter-table-statistics" id="markdown-toc-alter-table-statistics">Alter Table Statistics</a></li>
    </ul>
  </li>
</ul>

<h2 id="structure-of-table-api-and-sql-programs">Structure of Table API and SQL Programs</h2>

<p>All Table API and SQL programs for batch and streaming follow the same pattern. The following code example shows the common structure of Table API and SQL programs.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// for batch programs use ExecutionEnvironment instead of StreamExecutionEnvironment</span>
<span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// create a TableEnvironment</span>
<span class="c1">// for batch programs use BatchTableEnvironment instead of StreamTableEnvironment</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// register a Table</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTable</span><span class="o">(</span><span class="s">"table1"</span><span class="o">,</span> <span class="o">...)</span>            <span class="c1">// or</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTableSource</span><span class="o">(</span><span class="s">"table2"</span><span class="o">,</span> <span class="o">...);</span>     <span class="c1">// or</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerCatalog</span><span class="o">(</span><span class="s">"extCat"</span><span class="o">,</span> <span class="o">...);</span>

<span class="c1">// create a Table from a Table API query</span>
<span class="n">Table</span> <span class="n">tapiResult</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="s">"table1"</span><span class="o">).</span><span class="na">select</span><span class="o">(...);</span>
<span class="c1">// create a Table from a SQL query</span>
<span class="n">Table</span> <span class="n">sqlResult</span>  <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">sqlQuery</span><span class="o">(</span><span class="s">"SELECT ... FROM table2 ... "</span><span class="o">);</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result</span>
<span class="n">tapiResult</span><span class="o">.</span><span class="na">writeToSink</span><span class="o">(...);</span>

<span class="c1">// execute</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">execute</span><span class="o">();</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// for batch programs use ExecutionEnvironment instead of StreamExecutionEnvironment
</span><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="c1">// create a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register a Table
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTable</span><span class="o">(</span><span class="s">"table1"</span><span class="o">,</span> <span class="o">...)</span>           <span class="c1">// or
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">"table2"</span><span class="o">,</span> <span class="o">...)</span>     <span class="c1">// or
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerCatalog</span><span class="o">(</span><span class="s">"extCat"</span><span class="o">,</span> <span class="o">...)</span> 

<span class="c1">// create a Table from a Table API query
</span><span class="k">val</span> <span class="n">tapiResult</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">scan</span><span class="o">(</span><span class="s">"table1"</span><span class="o">).</span><span class="n">select</span><span class="o">(...)</span>
<span class="c1">// Create a Table from a SQL query
</span><span class="k">val</span> <span class="n">sqlResult</span>  <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">"SELECT ... FROM table2 ..."</span><span class="o">)</span>

<span class="c1">// emit a Table API result Table to a TableSink, same for SQL result
</span><span class="n">tapiResult</span><span class="o">.</span><span class="n">writeToSink</span><span class="o">(...)</span>

<span class="c1">// execute
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">execute</span><span class="o">()</span></code></pre></figure>

  </div>
</div>

<p><strong>Notes:</strong></p>
<ol>
  <li>Table API and SQL queries can be easily integrated with and embedded into DataStream programs. Have a look at the <a href="#integration-with-datastream-api">Integration with DataStream API</a> section to learn how DataStreams and DataSets can be converted into Tables and vice versa.</li>
  <li>For bounded stream job, we should always use <code class="highlighter-rouge">TableEnvironment.execute()</code> to submit and run the job.</li>
</ol>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="create-a-tableenvironment">Create a TableEnvironment</h2>

<p>The <code class="highlighter-rouge">TableEnvironment</code> is a central concept of the Table API and SQL integration. It is responsible for:</p>

<ul>
  <li>Registering a <code class="highlighter-rouge">Table</code> in the internal catalog</li>
  <li>Registering a catalog</li>
  <li>Executing SQL queries</li>
  <li>Registering a user-defined (scalar, table, or aggregation) function</li>
  <li>Converting a <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code></li>
  <li>Holding a reference to an <code class="highlighter-rouge">ExecutionEnvironment</code> or <code class="highlighter-rouge">StreamExecutionEnvironment</code></li>
</ul>

<p>A <code class="highlighter-rouge">Table</code> is always bound to a specific <code class="highlighter-rouge">TableEnvironment</code>. It is not possible to combine tables of different TableEnvironments in the same query, e.g., to join or union them.</p>

<p>A <code class="highlighter-rouge">TableEnvironment</code> is created by calling the static <code class="highlighter-rouge">TableEnvironment.getTableEnvironment()</code> method with a <code class="highlighter-rouge">StreamExecutionEnvironment</code> or an <code class="highlighter-rouge">ExecutionEnvironment</code> and an optional <code class="highlighter-rouge">TableConfig</code>. The <code class="highlighter-rouge">TableConfig</code> can be used to configure the <code class="highlighter-rouge">TableEnvironment</code> or to customize the query optimization and translation process (see <a href="#query-optimization">Query Optimization</a>).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// ***************</span>
<span class="c1">// STREAMING QUERY</span>
<span class="c1">// ***************</span>
<span class="n">StreamExecutionEnvironment</span> <span class="n">sEnv</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="c1">// create a TableEnvironment for streaming queries</span>
<span class="n">StreamTableEnvironment</span> <span class="n">sTableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">sEnv</span><span class="o">);</span>

<span class="c1">// ***********</span>
<span class="c1">// BATCH QUERY</span>
<span class="c1">// ***********</span>
<span class="n">StreamExecutionEnvironment</span> <span class="n">sEnv</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="c1">// create a TableEnvironment for batch queries</span>
<span class="n">BatchTableEnvironment</span> <span class="n">bTableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getBatchTableEnvironment</span><span class="o">(</span><span class="n">sEnv</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// ***************
// STREAMING QUERY
// ***************
</span><span class="k">val</span> <span class="n">sEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="c1">// create a TableEnvironment for streaming queries
</span><span class="k">val</span> <span class="n">sTableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">sEnv</span><span class="o">)</span>

<span class="c1">// ***********
// BATCH QUERY
// ***********
</span><span class="k">val</span> <span class="n">sEnv</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="c1">// create a TableEnvironment for batch queries
</span><span class="k">val</span> <span class="n">bTableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getBatchTableEnvironment</span><span class="o">(</span><span class="n">sEnv</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="register-flink-tables-in-tableenvironment">Register Flink Tables in TableEnvironment</h2>

<p>Tables registered via <code class="highlighter-rouge">TableEnvironment</code> will actually be registered to the default catalog and database in <code class="highlighter-rouge">CatalogManager</code>. Flink provides a built-in <code class="highlighter-rouge">FlinkInMemoryCatalog</code>, which implements <code class="highlighter-rouge">ReadableWritableCatalog</code>, as the default catalog. Users can also change the default catalog and database through both Table API or Flink SQL.</p>

<p>Note that Flink tables may not be registered to all <code class="highlighter-rouge">ReadableWritableCatalog</code>. Currently Flink only supports registering tables in <code class="highlighter-rouge">FlinkInMemoryCatalog</code>.</p>

<p>There are two types of Flink tables, <em>input tables</em> and <em>output tables</em>. Input tables can be referenced in Table API and SQL queries and provide input data. Output tables can be used to emit the result of a Table API or SQL query to an external system.</p>

<p>An input table can be registered from various sources:</p>

<ul>
  <li>an existing <code class="highlighter-rouge">Table</code> object, usually the result of a Table API or SQL query.</li>
  <li>a <code class="highlighter-rouge">TableSource</code>, which accesses external data, such as a file, database, or messaging system.</li>
  <li>a <code class="highlighter-rouge">DataStream</code> from a DataStream program. Registering a <code class="highlighter-rouge">DataStream</code> is discussed in the <a href="#integration-with-datastream-and-dataset-api">Integration with DataStream API</a> section.</li>
</ul>

<p>An output table can be registered using a <code class="highlighter-rouge">TableSink</code>.</p>

<h3 id="register-a-table">Register a Table</h3>

<p>A <code class="highlighter-rouge">Table</code> is registered in a <code class="highlighter-rouge">TableEnvironment</code> as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Table is the result of a simple projection query </span>
<span class="n">Table</span> <span class="n">projTable</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="s">"X"</span><span class="o">).</span><span class="na">select</span><span class="o">(...);</span>

<span class="c1">// register the Table projTable as table "projectedX" to the default catalog and database of CatalogManager</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTable</span><span class="o">(</span><span class="s">"projectedTable"</span><span class="o">,</span> <span class="n">projTable</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table is the result of a simple projection query 
</span><span class="k">val</span> <span class="n">projTable</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">scan</span><span class="o">(</span><span class="s">"X"</span><span class="o">).</span><span class="n">select</span><span class="o">(...)</span>

<span class="c1">// register the Table projTable as table "projectedX" to the default catalog and database of CatalogManager
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTable</span><span class="o">(</span><span class="s">"projectedTable"</span><span class="o">,</span> <span class="n">projTable</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> A registered <code class="highlighter-rouge">Table</code> is treated similarly to a <code class="highlighter-rouge">VIEW</code> as known from relational database systems, i.e., the query that defines the <code class="highlighter-rouge">Table</code> is not optimized but will be inlined when another query references the registered <code class="highlighter-rouge">Table</code>. If multiple queries reference the same registered <code class="highlighter-rouge">Table</code>, it will be inlined for each referencing query and executed only once, i.e., the result of the registered <code class="highlighter-rouge">Table</code> will be shared.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="register-a-tablesource">Register a TableSource</h3>

<p>A <code class="highlighter-rouge">TableSource</code> provides access to external data which is stored in a storage system such as a database (MySQL, HBase, …), a file with a specific encoding (CSV, Apache [Parquet, Avro, ORC], …), or a messaging system (Apache Kafka, RabbitMQ, …).</p>

<p>Flink aims to provide TableSources for common data formats and storage systems. Please have a look at the <a href="//flink-china.org/doc/blink/dev/table/sourceSinks.html">Table Sources and Sinks</a> page for a list of supported TableSources and instructions for how to build a custom <code class="highlighter-rouge">TableSource</code>.</p>

<p>A <code class="highlighter-rouge">TableSource</code> is registered in a <code class="highlighter-rouge">TableEnvironment</code> as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// create a TableSource</span>
<span class="n">TableSource</span> <span class="n">csvSource</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CsvTableSource</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="o">...);</span>

<span class="c1">// register the TableSource as table "CsvTable" to the default catalog and database of CatalogManager</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTableSource</span><span class="o">(</span><span class="s">"CsvTable"</span><span class="o">,</span> <span class="n">csvSource</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// create a TableSource
</span><span class="k">val</span> <span class="n">csvSource</span><span class="k">:</span> <span class="kt">TableSource</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CsvTableSource</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="o">...)</span>

<span class="c1">// register the TableSource as table "CsvTable" to the default catalog and database of CatalogManager
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSource</span><span class="o">(</span><span class="s">"CsvTable"</span><span class="o">,</span> <span class="n">csvSource</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="register-a-tablesink">Register a TableSink</h3>

<p>A registered <code class="highlighter-rouge">TableSink</code> can be used to <a href="common.html#emit-a-table">emit the result of a Table API or SQL query</a> to an external storage system, such as a database, key-value store, message queue, or file system (in different encodings, e.g., CSV, Apache [Parquet, Avro, ORC], …).</p>

<p>Flink aims to provide TableSinks for common data formats and storage systems. Please see the documentation about <a href="//flink-china.org/doc/blink/dev/table/sourceSinks.html">Table Sources and Sinks</a> page for details about available sinks and instructions for how to implement a custom <code class="highlighter-rouge">TableSink</code>.</p>

<p>A <code class="highlighter-rouge">TableSink</code> is registered in a <code class="highlighter-rouge">TableEnvironment</code> as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// create a TableSink</span>
<span class="n">TableSink</span> <span class="n">csvSink</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CsvTableSink</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="o">...);</span>

<span class="c1">// define the field names and types</span>
<span class="n">String</span><span class="o">[]</span> <span class="n">fieldNames</span> <span class="o">=</span> <span class="o">{</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">,</span> <span class="s">"c"</span><span class="o">};</span>
<span class="n">DataType</span><span class="o">[]</span> <span class="n">fieldTypes</span> <span class="o">=</span> <span class="o">{</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">LONG</span><span class="o">};</span>

<span class="c1">// register the TableSink as table "CsvSinkTable" to the default catalog and database of CatalogManager</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTableSink</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">,</span> <span class="n">fieldNames</span><span class="o">,</span> <span class="n">fieldTypes</span><span class="o">,</span> <span class="n">csvSink</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// create a TableSink
</span><span class="k">val</span> <span class="n">csvSink</span><span class="k">:</span> <span class="kt">TableSink</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CsvTableSink</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="o">...)</span>

<span class="c1">// define the field names and types
</span><span class="k">val</span> <span class="n">fieldNames</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">,</span> <span class="s">"c"</span><span class="o">)</span>
<span class="k">val</span> <span class="n">fieldTypes</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">DataType</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">LONG</span><span class="o">)</span>

<span class="c1">// register the TableSink as table "CsvSinkTable" to the default catalog and database of CatalogManager
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSink</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">,</span> <span class="n">fieldNames</span><span class="o">,</span> <span class="n">fieldTypes</span><span class="o">,</span> <span class="n">csvSink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="catalogs">Catalogs</h2>

<p>For catalogs, see <a href="//flink-china.org/doc/blink/dev/table/catalog.html">Catalog</a></p>

<h2 id="query-a-table">Query a Table</h2>

<h3 id="table-api">Table API</h3>

<p>The Table API is a language-integrated query API for Scala and Java. In contrast to SQL, queries are not specified as Strings but are composed step-by-step in the host language.</p>

<p>The API is based on the <code class="highlighter-rouge">Table</code> class which represents a table (streaming or batch) and offers methods to apply relational operations. These methods return a new <code class="highlighter-rouge">Table</code> object, which represents the result of applying the relational operation on the input <code class="highlighter-rouge">Table</code>. Some relational operations are composed of multiple method calls such as <code class="highlighter-rouge">table.groupBy(...).select()</code>, where <code class="highlighter-rouge">groupBy(...)</code> specifies a grouping of <code class="highlighter-rouge">table</code>, and <code class="highlighter-rouge">select(...)</code> the projection on the grouping of <code class="highlighter-rouge">table</code>.</p>

<p>The <a href="//flink-china.org/doc/blink/dev/table/tableApi.html">Table API</a> document describes all Table API operations that are supported on streaming and batch tables.</p>

<p>The following example shows a simple Table API aggregation query:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// register Orders table</span>

<span class="c1">// scan registered Orders table</span>
<span class="n">Table</span> <span class="n">orders</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">);</span>
<span class="c1">// compute revenue for all customers from France</span>
<span class="n">Table</span> <span class="n">revenue</span> <span class="o">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="s">"cCountry === 'FRANCE'"</span><span class="o">)</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="s">"cID, cName"</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">"cID, cName, revenue.sum AS revSum"</span><span class="o">);</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register Orders table
</span>
<span class="c1">// scan registered Orders table
</span><span class="k">val</span> <span class="n">orders</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">scan</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">)</span>
<span class="c1">// compute revenue for all customers from France
</span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">orders</span>
  <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="ss">'cCountry </span><span class="o">===</span> <span class="s">"FRANCE"</span><span class="o">)</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="ss">'cID,</span> <span class="ss">'cName)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="ss">'cID,</span> <span class="ss">'cName,</span> <span class="ss">'revenue.</span><span class="n">sum</span> <span class="nc">AS</span> <span class="ss">'revSum)</span>

<span class="c1">// emit or convert Table
</span><span class="o">//</span> <span class="n">execute</span> <span class="n">query</span></code></pre></figure>

    <p><strong>Note:</strong> The Scala Table API uses Scala Symbols, which start with a single tick (<code class="highlighter-rouge">'</code>) to reference the attributes of a <code class="highlighter-rouge">Table</code>. The Table API uses Scala implicits. Make sure to import <code class="highlighter-rouge">org.apache.flink.api.scala._</code> and <code class="highlighter-rouge">org.apache.flink.table.api.scala._</code> in order to use Scala implicit conversions.</p>
  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="sql">SQL</h3>

<p>Flink’s SQL integration is based on <a href="https://calcite.apache.org">Apache Calcite</a>, which implements the SQL standard. SQL queries are specified as regular Strings.</p>

<p>The <a href="//flink-china.org/doc/blink/dev/table/sql.html">SQL</a> document describes Flink’s SQL support for streaming and batch tables.</p>

<p>The following example shows how to specify a query and return the result as a <code class="highlighter-rouge">Table</code>.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// register Orders table</span>

<span class="c1">// compute revenue for all customers from France</span>
<span class="n">Table</span> <span class="n">revenue</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">sqlQuery</span><span class="o">(</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span> <span class="o">+</span>
    <span class="s">"FROM Orders "</span> <span class="o">+</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span> <span class="o">+</span>
    <span class="s">"GROUP BY cID, cName"</span>
  <span class="o">);</span>

<span class="c1">// emit or convert Table</span>
<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register Orders table
</span>
<span class="c1">// compute revenue for all customers from France
</span><span class="k">val</span> <span class="n">revenue</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlQuery</span><span class="o">(</span><span class="s">"""
  |SELECT cID, cName, SUM(revenue) AS revSum
  |FROM Orders
  |WHERE cCountry = 'FRANCE'
  |GROUP BY cID, cName
  """</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="c1">// emit or convert Table
</span><span class="o">//</span> <span class="n">execute</span> <span class="n">query</span></code></pre></figure>

  </div>
</div>

<p>The following example shows how to specify an update query that inserts its result into a registered table.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// register "Orders" table</span>
<span class="c1">// register "RevenueFrance" output table</span>

<span class="c1">// compute revenue for all customers from France and emit to "RevenueFrance"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">sqlUpdate</span><span class="o">(</span>
    <span class="s">"INSERT INTO RevenueFrance "</span> <span class="o">+</span>
    <span class="s">"SELECT cID, cName, SUM(revenue) AS revSum "</span> <span class="o">+</span>
    <span class="s">"FROM Orders "</span> <span class="o">+</span>
    <span class="s">"WHERE cCountry = 'FRANCE' "</span> <span class="o">+</span>
    <span class="s">"GROUP BY cID, cName"</span>
  <span class="o">);</span>

<span class="c1">// execute query</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// register "Orders" table
// register "RevenueFrance" output table
</span>
<span class="c1">// compute revenue for all customers from France and emit to "RevenueFrance"
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">sqlUpdate</span><span class="o">(</span><span class="s">"""
  |INSERT INTO RevenueFrance
  |SELECT cID, cName, SUM(revenue) AS revSum
  |FROM Orders
  |WHERE cCountry = 'FRANCE'
  |GROUP BY cID, cName
  """</span><span class="o">.</span><span class="n">stripMargin</span><span class="o">)</span>

<span class="o">//</span> <span class="n">execute</span> <span class="n">query</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="mixing-table-api-and-sql">Mixing Table API and SQL</h3>

<p>Table API and SQL queries can be easily mixed because both return <code class="highlighter-rouge">Table</code> objects:</p>

<ul>
  <li>A Table API query can be defined on the <code class="highlighter-rouge">Table</code> object returned by a SQL query.</li>
  <li>A SQL query can be defined on the result of a Table API query by <a href="#register-a-table">registering the resulting Table</a> in the <code class="highlighter-rouge">TableEnvironment</code> and referencing it in the <code class="highlighter-rouge">FROM</code> clause of the SQL query.</li>
</ul>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="emit-a-table">Emit a Table</h2>

<p>A <code class="highlighter-rouge">Table</code> is emitted by writing it to a <code class="highlighter-rouge">TableSink</code>. A <code class="highlighter-rouge">TableSink</code> is a generic interface to support a wide variety of file formats (e.g. CSV, Apache Parquet, Apache Avro), storage systems (e.g., JDBC, Apache HBase, Apache Cassandra, Elasticsearch), or messaging systems (e.g., Apache Kafka, RabbitMQ).</p>

<p>A batch <code class="highlighter-rouge">Table</code> can only be written to a <code class="highlighter-rouge">BatchTableSink</code>, while a streaming <code class="highlighter-rouge">Table</code> requires either an <code class="highlighter-rouge">AppendStreamTableSink</code>, a <code class="highlighter-rouge">RetractStreamTableSink</code>, or an <code class="highlighter-rouge">UpsertStreamTableSink</code>.</p>

<p>Please see the documentation about <a href="//flink-china.org/doc/blink/dev/table/sourceSinks.html">Table Sources &amp; Sinks</a> for details about available sinks and instructions for how to implement a custom <code class="highlighter-rouge">TableSink</code>.</p>

<p>There are two ways to emit a table:</p>

<ol>
  <li>The <code class="highlighter-rouge">Table.writeToSink(TableSink sink)</code> method emits the table using the provided <code class="highlighter-rouge">TableSink</code> and automatically configures the sink with the schema of the table to emit.</li>
  <li>The <code class="highlighter-rouge">Table.insertInto(String sinkTable)</code> method looks up a <code class="highlighter-rouge">TableSink</code> that was registered with a specific schema under the provided name in the <code class="highlighter-rouge">TableEnvironment</code>’s catalog. The schema of the table to emit is validated against the schema of the registered <code class="highlighter-rouge">TableSink</code>.</li>
</ol>

<p>The following examples shows how to emit a <code class="highlighter-rouge">Table</code>:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries</span>
<span class="n">Table</span> <span class="n">result</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// create a TableSink</span>
<span class="n">TableSink</span> <span class="n">sink</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CsvTableSink</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="s">"|"</span><span class="o">);</span>

<span class="c1">// METHOD 1:</span>
<span class="c1">//   Emit the result Table to the TableSink via the writeToSink() method</span>
<span class="n">result</span><span class="o">.</span><span class="na">writeToSink</span><span class="o">(</span><span class="n">sink</span><span class="o">);</span>

<span class="c1">// METHOD 2:</span>
<span class="c1">//   Register the TableSink with a specific schema</span>
<span class="n">String</span><span class="o">[]</span> <span class="n">fieldNames</span> <span class="o">=</span> <span class="o">{</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">,</span> <span class="s">"c"</span><span class="o">};</span>
<span class="n">DataType</span><span class="o">[]</span> <span class="n">fieldTypes</span> <span class="o">=</span> <span class="o">{</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">INT</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">STRING</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">LONG</span><span class="o">};</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerTableSink</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">,</span> <span class="n">fieldNames</span><span class="o">,</span> <span class="n">fieldTypes</span><span class="o">,</span> <span class="n">sink</span><span class="o">);</span>
<span class="c1">//   Emit the result Table to the registered TableSink via the insertInto() method</span>
<span class="n">result</span><span class="o">.</span><span class="na">insertInto</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">);</span>

<span class="c1">// execute the program</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// compute a result Table using Table API operators and/or SQL queries
</span><span class="k">val</span> <span class="n">result</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// create a TableSink
</span><span class="k">val</span> <span class="n">sink</span><span class="k">:</span> <span class="kt">TableSink</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CsvTableSink</span><span class="o">(</span><span class="s">"/path/to/file"</span><span class="o">,</span> <span class="n">fieldDelim</span> <span class="k">=</span> <span class="s">"|"</span><span class="o">)</span>

<span class="c1">// METHOD 1:
//   Emit the result Table to the TableSink via the writeToSink() method
</span><span class="n">result</span><span class="o">.</span><span class="n">writeToSink</span><span class="o">(</span><span class="n">sink</span><span class="o">)</span>

<span class="c1">// METHOD 2:
//   Register the TableSink with a specific schema
</span><span class="k">val</span> <span class="n">fieldNames</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"a"</span><span class="o">,</span> <span class="s">"b"</span><span class="o">,</span> <span class="s">"c"</span><span class="o">)</span>
<span class="k">val</span> <span class="n">fieldTypes</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">DataType</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">DataTypes</span><span class="o">.</span><span class="nc">INT</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">STRING</span><span class="o">,</span> <span class="nc">DataTypes</span><span class="o">.</span><span class="nc">LONG</span><span class="o">)</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="n">registerTableSink</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">,</span> <span class="n">fieldNames</span><span class="o">,</span> <span class="n">fieldTypes</span><span class="o">,</span> <span class="n">sink</span><span class="o">)</span>
<span class="c1">//   Emit the result Table to the registered TableSink via the insertInto() method
</span><span class="n">result</span><span class="o">.</span><span class="n">insertInto</span><span class="o">(</span><span class="s">"CsvSinkTable"</span><span class="o">)</span>

<span class="o">//</span> <span class="n">execute</span> <span class="n">the</span> <span class="n">program</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="translate-and-execute-a-query">Translate and Execute a Query</h2>

<p>Table API and SQL queries are translated into <a href="//flink-china.org/doc/blink/dev/datastream_api.html">DataStream</a> programs no matter whether their input is a streaming or batch input. A query is internally represented as a logical query plan and is translated in two phases:</p>

<ol>
  <li>optimization of the logical plan,</li>
  <li>translation into a DataStream program.</li>
</ol>

<p>A Table API or SQL query is translated when:</p>

<ul>
  <li>a <code class="highlighter-rouge">Table</code> is emitted to a <code class="highlighter-rouge">TableSink</code>, i.e., when <code class="highlighter-rouge">Table.writeToSink()</code> or <code class="highlighter-rouge">Table.insertInto()</code> is called.</li>
  <li>a SQL update query is specified, i.e., when <code class="highlighter-rouge">TableEnvironment.sqlUpdate()</code> is called.</li>
  <li>a <code class="highlighter-rouge">Table</code> is converted into a <code class="highlighter-rouge">DataStream</code>(see <a href="#integration-with-datastream-api">Integration with DataStream API</a>).</li>
</ul>

<p>Once translated, a Table API or SQL query is handled like a regular DataStream program and is executed when <code class="highlighter-rouge">StreamExecutionEnvironment.execute()</code> is called.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="integration-with-datastream-api">Integration with DataStream API</h2>

<p>Table API and SQL queries can be easily integrated with and embedded into <a href="//flink-china.org/doc/blink/dev/datastream_api.html">DataStream</a> programs. For instance, it is possible to query an external table (for example from a RDBMS), do some pre-processing, such as filtering, projecting, aggregating, or joining with meta data, and then further process the data with either the DataStream API (and any of the libraries built on top of these APIs, such as CEP or Gelly). Inversely, a Table API or SQL query can also be applied on the result of a DataStream program.</p>

<p>This interaction can be achieved by converting a <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code> and vice versa. In this section, we describe how these conversions are done.</p>

<h3 id="implicit-conversion-for-scala">Implicit Conversion for Scala</h3>

<p>The Scala Table API features implicit conversions for the <code class="highlighter-rouge">DataStream</code>, and <code class="highlighter-rouge">Table</code> classes. These conversions are enabled by importing the package <code class="highlighter-rouge">org.apache.flink.table.api.scala._</code> in addition to <code class="highlighter-rouge">org.apache.flink.api.scala._</code> for the Scala DataStream API.</p>

<h3 id="register-a-datastream-as-table">Register a DataStream as Table</h3>

<p>A <code class="highlighter-rouge">DataStream</code> can be registered in a <code class="highlighter-rouge">TableEnvironment</code> as a Table. The schema of the resulting table depends on the data type of the registered <code class="highlighter-rouge">DataStream</code>. Please check the section about <a href="#mapping-of-data-types-to-table-schema">mapping of data types to table schema</a> for details.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment</span>
<span class="c1">// registration of a DataStream in a BatchTableEnvironment is equivalent</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// register the DataStream as Table "myTable" with fields "f0", "f1"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerDataStream</span><span class="o">(</span><span class="s">"myTable"</span><span class="o">,</span> <span class="n">stream</span><span class="o">);</span>

<span class="c1">// register the DataStream as table "myTable2" with fields "myLong", "myString"</span>
<span class="n">tableEnv</span><span class="o">.</span><span class="na">registerDataStream</span><span class="o">(</span><span class="s">"myTable2"</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> <span class="s">"myLong, myString"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
// registration of a bounded DataStream is equivalent
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// register the DataStream as Table "myTable" with fields "f0", "f1"
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerDataStream</span><span class="o">(</span><span class="s">"myTable"</span><span class="o">,</span> <span class="n">stream</span><span class="o">)</span>

<span class="c1">// register the DataStream as table "myTable2" with fields "myLong", "myString"
</span><span class="n">tableEnv</span><span class="o">.</span><span class="n">registerDataStream</span><span class="o">(</span><span class="s">"myTable2"</span><span class="o">,</span> <span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong,</span> <span class="ss">'myString)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> The name of a <code class="highlighter-rouge">DataStream</code> <code class="highlighter-rouge">Table</code> must not match the <code class="highlighter-rouge">^_DataStreamTable_[0-9]+</code> pattern and the name of a <code class="highlighter-rouge">DataSet</code> <code class="highlighter-rouge">Table</code> must not match the <code class="highlighter-rouge">^_DataSetTable_[0-9]+</code> pattern. These patterns are reserved for internal use only.</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="convert-a-datastream-into-a-table">Convert a DataStream into a Table</h3>

<p>Instead of registering a <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">TableEnvironment</code>, it can also be directly converted into a <code class="highlighter-rouge">Table</code>. This is convenient if you want to use the Table in a Table API query.</p>

<h4 id="convert-a-datastream-into-a-tableunbounded">Convert a DataStream into a table(unbounded)</h4>
<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Convert the DataStream into a Table with default fields "f0", "f1"</span>
<span class="n">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// Convert the DataStream into a Table with fields "myLong", "myString"</span>
<span class="n">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myLong, myString"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get StreamTableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert the DataStream into a Table with default fields '_1, '_2
</span><span class="k">val</span> <span class="n">table1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert the DataStream into a Table with fields 'myLong, 'myString
</span><span class="k">val</span> <span class="n">table2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong,</span> <span class="ss">'myString)</span></code></pre></figure>

  </div>
</div>

<h4 id="convert-a-datastream-into-a-tablebounded">Convert a DataStream into a table(bounded)</h4>
<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get BatchTableEnvironment</span>
<span class="n">BatchTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getBatchTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Convert the DataStream into a Table with default fields "f0", "f1"</span>
<span class="n">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromBoundedStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// Convert the DataStream into a Table with fields "myLong", "myString"</span>
<span class="n">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromBoundedStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myLong, myString"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get BatchTableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getBatchTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert the DataStream into a Table with default fields '_1, '_2
</span><span class="k">val</span> <span class="n">table1</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromBoundedStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert the DataStream into a Table with fields 'myLong, 'myString
</span><span class="k">val</span> <span class="n">table2</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromBoundedStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong,</span> <span class="ss">'myString)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="convert-a-table-into-a-datastream">Convert a Table into a DataStream</h3>

<p>A <code class="highlighter-rouge">Table</code> can be converted into a <code class="highlighter-rouge">DataStream</code>. In this way, custom DataStream program can be run on the result of a Table API or SQL query.</p>

<p>When converting a <code class="highlighter-rouge">Table</code> into a <code class="highlighter-rouge">DataStream</code>, you need to specify the data type of the resulting <code class="highlighter-rouge">DataStream</code>, i.e., the data type into which the rows of the <code class="highlighter-rouge">Table</code> are to be converted. Often the most convenient conversion type is <code class="highlighter-rouge">Row</code>. The following list gives an overview of the features of the different options:</p>

<ul>
  <li><strong>Row</strong>: fields are mapped by position, arbitrary number of fields, support for <code class="highlighter-rouge">null</code> values, no type-safe access.</li>
  <li><strong>POJO</strong>: fields are mapped by name (POJO fields must be named as <code class="highlighter-rouge">Table</code> fields), arbitrary number of fields, support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Case Class</strong>: fields are mapped by position, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Tuple</strong>: fields are mapped by position, limitation to 22 (Scala) or 25 (Java) fields, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
  <li><strong>Atomic Type</strong>: <code class="highlighter-rouge">Table</code> must have a single field, no support for <code class="highlighter-rouge">null</code> values, type-safe access.</li>
</ul>

<h4 id="convert-a-table-into-a-datastreamunbounded">Convert a Table into a DataStream(unbounded)</h4>

<p>A <code class="highlighter-rouge">Table</code> that is the result of a streaming query will be updated dynamically, i.e., it is changing as new records arrive on the query’s input streams. Hence, the <code class="highlighter-rouge">DataStream</code> into which such a dynamic query is converted needs to encode the updates of the table.</p>

<p>There are two modes to convert a <code class="highlighter-rouge">Table</code> into a <code class="highlighter-rouge">DataStream</code>:</p>

<ol>
  <li><strong>Append Mode</strong>: This mode can only be used if the dynamic <code class="highlighter-rouge">Table</code> is only modified by <code class="highlighter-rouge">INSERT</code> changes, i.e, it is append-only and previously emitted results are never updated.</li>
  <li><strong>Retract Mode</strong>: This mode can always be used. It encodes <code class="highlighter-rouge">INSERT</code> and <code class="highlighter-rouge">DELETE</code> changes with a <code class="highlighter-rouge">boolean</code> flag.</li>
</ol>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get StreamTableEnvironment. </span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into an append DataStream of Row by specifying the class</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dsRow</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">toAppendStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">Row</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2&lt;String, Integer&gt; </span>
<span class="c1">//   via a TypeInformation</span>
<span class="n">TupleTypeInfo</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">tupleType</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TupleTypeInfo</span><span class="o">&lt;&gt;(</span>
  <span class="n">Types</span><span class="o">.</span><span class="na">STRING</span><span class="o">(),</span>
  <span class="n">Types</span><span class="o">.</span><span class="na">INT</span><span class="o">());</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">dsTuple</span> <span class="o">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="na">toAppendStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">tupleType</span><span class="o">);</span>

<span class="c1">// convert the Table into a retract DataStream of Row.</span>
<span class="c1">//   A retract stream of type X is a DataStream&lt;Tuple2&lt;Boolean, X&gt;&gt;. </span>
<span class="c1">//   The boolean field indicates the type of the change. </span>
<span class="c1">//   True is INSERT, false is DELETE.</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Boolean</span><span class="o">,</span> <span class="n">Row</span><span class="o">&gt;&gt;</span> <span class="n">retractStream</span> <span class="o">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="na">toRetractStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">Row</span><span class="o">.</span><span class="na">class</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment. 
// registration of a bounded DataStream is equivalent
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into an append DataStream of Row
</span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into an append DataStream of Tuple2[String, Int]
</span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="n">dsTuple</span> <span class="k">=</span> 
  <span class="n">tableEnv</span><span class="o">.</span><span class="n">toAppendStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">)</span>

<span class="c1">// convert the Table into a retract DataStream of Row.
//   A retract stream of type X is a DataStream[(Boolean, X)]. 
//   The boolean field indicates the type of the change. 
//   True is INSERT, false is DELETE.
</span><span class="k">val</span> <span class="n">retractStream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Boolean</span>, <span class="kt">Row</span><span class="o">)]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toRetractStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><strong>Note:</strong> A detailed discussion about dynamic tables and their properties is given in the <a href="//flink-china.org/doc/blink/dev/table/streaming.html">Streaming Queries</a> document.</p>

<h4 id="convert-a-table-into-a-datastreambounded">Convert a Table into a DataStream(bounded)</h4>

<p>A <code class="highlighter-rouge">Table</code> is converted into a bounded <code class="highlighter-rouge">DataStream</code> as follows:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get BatchTableEnvironment</span>
<span class="n">BatchTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Table with two fields (String name, Integer age)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into a bounded DataStream by specifying a BatchTableSink.</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dsRow</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">toBoundedStream</span><span class="o">(</span><span class="n">table</span><span class="o">,</span> <span class="n">tSink</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get TableEnvironment 
// registration of a bounded DataStream is equivalent
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Table with two fields (String name, Integer age)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">tableSink</span><span class="k">:</span> <span class="kt">BatchTableSink</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert the Table into a bounded DataStream of Row
</span><span class="k">val</span> <span class="n">dsRow</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toBoundedStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">](</span><span class="n">table</span><span class="o">,</span> <span class="n">tableSink</span><span class="o">)</span>

<span class="c1">// convert the Table into a bounded DataStream of Tuple2[String, Int]
</span><span class="k">val</span> <span class="n">dsTuple</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">toBoundedStream</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)](</span><span class="n">table</span><span class="o">,</span> <span class="n">tableSink</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="mapping-of-data-types-to-table-schema">Mapping of Data Types to Table Schema</h3>

<p>Flink’s DataStream APIs support very diverse types. Composite types such as Tuples (built-in Scala and Flink Java tuples), POJOs, Scala case classes, and Flink’s Row type allow for nested data structures with multiple fields that can be accessed in table expressions. Other types are treated as atomic types. In the following, we describe how the Table API converts these types into an internal row representation and show examples of converting a <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code>.</p>

<p>The mapping of a data type to a table schema can happen in two ways: <strong>based on the field positions</strong> or <strong>based on the field names</strong>.</p>

<p><strong>Position-based Mapping</strong></p>

<p>Position-based mapping can be used to give fields a more meaningful name while keeping the field order. This mapping is available for composite data types <em>with a defined field order</em> as well as atomic types. Composite data types such as tuples, rows, and case classes have such a field order. However, fields of a POJO must be mapped based on the field names (see next section).</p>

<p>When defining a position-based mapping, the specified names must not exist in the input data type, otherwise the API will assume that the mapping should happen based on the field names. If no field names are specified, the default field names and field order of the composite type are used or <code class="highlighter-rouge">f0</code> for atomic types.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0" and "f1"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field names "myLong" and "myInt"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myLong, myInt"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "_1" and "_2"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names "myLong" and "myInt"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong 'myInt)</span></code></pre></figure>

  </div>
</div>

<p><strong>Name-based Mapping</strong></p>

<p>Name-based mapping can be used for any data type including POJOs. It is the most flexible way of defining a table schema mapping. All fields in the mapping are referenced by name and can be possibly renamed using an alias <code class="highlighter-rouge">as</code>. Fields can be reordered and projected out.</p>

<p>If no field names are specified, the default field names and field order of the composite type are used or <code class="highlighter-rouge">f0</code> for atomic types.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0" and "f1"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field "f1" only</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with swapped fields</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1, f0"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names "myInt" and "myLong"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1 as myInt, f0 as myLong"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "_1" and "_2"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field "_2" only
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2)</span>

<span class="c1">// convert DataStream into Table with swapped fields
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2,</span> <span class="ss">'_1)</span>

<span class="c1">// convert DataStream into Table with swapped fields and field names "myInt" and "myLong"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2 </span><span class="n">as</span> <span class="ss">'myInt,</span> <span class="ss">'_1 </span><span class="n">as</span> <span class="ss">'myLong)</span></code></pre></figure>

  </div>
</div>

<h4 id="atomic-types">Atomic Types</h4>

<p>Flink treats primitives (<code class="highlighter-rouge">Integer</code>, <code class="highlighter-rouge">Double</code>, <code class="highlighter-rouge">String</code>) or generic types (types that cannot be analyzed and decomposed) as atomic types. A <code class="highlighter-rouge">DataStream</code> of an atomic type is converted into a <code class="highlighter-rouge">Table</code> with a single attribute. The type of the attribute is inferred from the atomic type and the name of the attribute can be specified.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field name "f0"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with field name "myLong"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myLong"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field name "f0"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field name "myLong"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong)</span></code></pre></figure>

  </div>
</div>

<h4 id="tuples-scala-and-java-and-case-classes-scala-only">Tuples (Scala and Java) and Case Classes (Scala only)</h4>

<p>Flink supports Scala’s built-in tuples and provides its own tuple classes for Java. DataStreams of both kinds of tuples can be converted into tables. Fields can be renamed by providing names for all fields (mapping based on position). If no field names are specified, the default field names are used. If the original field names (<code class="highlighter-rouge">f0</code>, <code class="highlighter-rouge">f1</code>, … for Flink Tuples and <code class="highlighter-rouge">_1</code>, <code class="highlighter-rouge">_2</code>, … for Scala Tuples) are referenced, the API assumes that the mapping is name-based instead of position-based. Name-based mapping allows for reordering fields and projection with alias (<code class="highlighter-rouge">as</code>).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "f0", "f1"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed field names "myLong", "myString" (position-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myLong, myString"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with reordered fields "f1", "f0" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1, f0"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with projected field "f1" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myString", "myLong" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"f1 as 'myString', f0 as 'myLong'"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">String</span><span class="o">)]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with renamed default field names '_1, '_2
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names "myLong", "myString" (position-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myLong,</span> <span class="ss">'myString)</span>

<span class="c1">// convert DataStream into Table with reordered fields "_2", "_1" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2,</span> <span class="ss">'_1)</span>

<span class="c1">// convert DataStream into Table with projected field "_2" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myString", "myLong" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'_2 </span><span class="n">as</span> <span class="ss">'myString,</span> <span class="ss">'_1 </span><span class="n">as</span> <span class="ss">'myLong)</span>

<span class="c1">// define case class
</span><span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">streamCC</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names 'name, 'age
</span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with field names 'myName, 'myAge (position-based)
</span><span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">streamCC</span><span class="o">,</span> <span class="ss">'myName,</span> <span class="ss">'myAge)</span>

<span class="c1">// convert DataStream into Table with reordered and aliased fields "myAge", "myName" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'age </span><span class="n">as</span> <span class="ss">'myAge,</span> <span class="ss">'name </span><span class="n">as</span> <span class="ss">'myName)</span></code></pre></figure>

  </div>
</div>

<h4 id="pojo-java-and-scala">POJO (Java and Scala)</h4>

<p>Flink supports POJOs as composite types. The rules for what determines a POJO are documented <a href="//flink-china.org/doc/blink/dev/api_concepts.html#pojos">here</a>.</p>

<p>When converting a POJO <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code> without specifying field names, the names of the original POJO fields are used. The name mapping requires the original names and cannot be done by positions. Fields can be renamed using an alias (with the <code class="highlighter-rouge">as</code> keyword), reordered, and projected.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Person is a POJO with fields "name" and "age"</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "age", "name" (fields are ordered by name!)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed fields "myAge", "myName" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"age as myAge, name as myName"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"name"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"name as myName"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// Person is a POJO with field names "name" and "age"
</span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "age", "name" (fields are ordered by name!)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed fields "myAge", "myName" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'age </span><span class="n">as</span> <span class="ss">'myAge,</span> <span class="ss">'name </span><span class="n">as</span> <span class="ss">'myName)</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'name)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'name </span><span class="n">as</span> <span class="ss">'myName)</span></code></pre></figure>

  </div>
</div>

<h4 id="row">Row</h4>

<p>The <code class="highlighter-rouge">Row</code> data type supports an arbitrary number of fields and fields with <code class="highlighter-rouge">null</code> values. Field names can be specified via a <code class="highlighter-rouge">RowTypeInfo</code> or when converting a <code class="highlighter-rouge">Row</code> <code class="highlighter-rouge">DataStream</code> into a <code class="highlighter-rouge">Table</code>. The row type supports mapping of fields by position and by name. Fields can be renamed by providing names for all fields (mapping based on position) or selected individually for projection/ordering/renaming (mapping based on name).</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// get a StreamTableEnvironment, works for BatchTableEnvironment equivalently</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// DataStream of Row with two fields "name" and "age" specified in `RowTypeInfo`</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "name", "age"</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed field names "myName", "myAge" (position-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"myName, myAge"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with renamed fields "myName", "myAge" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"name as myName, age as myAge"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"name"</span><span class="o">);</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">"name as myName"</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// get a TableEnvironment
</span><span class="k">val</span> <span class="n">tableEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="c1">// DataStream of Row with two fields "name" and "age" specified in `RowTypeInfo`
</span><span class="k">val</span> <span class="n">stream</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">Row</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="c1">// convert DataStream into Table with default field names "name", "age"
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">)</span>

<span class="c1">// convert DataStream into Table with renamed field names "myName", "myAge" (position-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'myName,</span> <span class="ss">'myAge)</span>

<span class="c1">// convert DataStream into Table with renamed fields "myName", "myAge" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'name </span><span class="n">as</span> <span class="ss">'myName,</span> <span class="ss">'age </span><span class="n">as</span> <span class="ss">'myAge)</span>

<span class="c1">// convert DataStream into Table with projected field "name" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'name)</span>

<span class="c1">// convert DataStream into Table with projected and renamed field "myName" (name-based)
</span><span class="k">val</span> <span class="n">table</span><span class="k">:</span> <span class="kt">Table</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="n">fromDataStream</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="ss">'name </span><span class="n">as</span> <span class="ss">'myName)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="query-optimization">Query Optimization</h2>

<p>The foundation of Apache Flink query optimization is Apache Calcite. In addition to apply Calcite in optimization, Flink also does a lot to enhance it.</p>

<p>Fist of all, Flink does a series of rule-based optimization and cost-based optimization including:</p>
<ul>
  <li>special subquery rewriting, including two part: 1. converts IN and EXISTS into left semi-join 2.converts NOT IN and NOT EXISTS into left anti-join. Note: only IN/EXISTS/NOT IN/NOT EXISTS in conjunctive condition is supported.</li>
  <li>normal subquery decorrelation based on Calcite</li>
  <li>projection pruning</li>
  <li>filter push down</li>
  <li>partition pruning</li>
  <li>join reorder if it is enabled (<code class="highlighter-rouge">sql.optimizer.join-reorder.enabled</code> is true)</li>
  <li>skew join optimization</li>
  <li>other kinds of query rewriting</li>
</ul>

<p>Secondly, Flink introduces rich statistics of data source and propagate those statistics up to the whole plan based on all kinds of extended <code class="highlighter-rouge">MetadataHandler</code>s. Optimizer could choose better plan based on those metadata.</p>

<p>Finally, Flink provides fine-grain cost of each operator, which takes io, cpu, network and memory into account. Cost-based optimization could choose better plan based on fine-grain cost definition .</p>

<p>It is possible to customize optimization programs referencing to <code class="highlighter-rouge">FlinkBatchPrograms</code>(default optimization programs for batch) or <code class="highlighter-rouge">FlinkStreamPrograms</code>(default optimization programs for stream), and replace the default optimization programs by providing a <code class="highlighter-rouge">CalciteConfig</code> object. This can be created via a builder by calling <code class="highlighter-rouge">CalciteConfig.createBuilder())</code> and is provided to the TableEnvironment by calling <code class="highlighter-rouge">tableEnv.getConfig.setCalciteConfig(calciteConfig)</code>.</p>

<h3 id="reuse-subplan">Reuse SubPlan</h3>
<p>Flink will try to find duplicate sub-plans by the digest of physical sub-plan and reuse them if Reuse sub-plan is enabled (<code class="highlighter-rouge">sql.optimizer.reuse.sub-plan.enabled</code> is true, default is false).</p>

<p><strong>Note:</strong> Reuse sub-plan on Batch is supported now.</p>

<p>The following code example shows the physical plan when reuse sub-plan is enabled.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="c1">// create a BatchTableEnvironment</span>
<span class="n">BatchTableEnvironment</span> <span class="n">tableEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getBatchTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// register Orders table</span>

<span class="c1">// this part is reusable</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">scan</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">)</span>
	<span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="s">"cID, cName"</span><span class="o">)</span>
	<span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">"cID, cName, revenue.sum as revSum, revenue.avg as revAvg"</span><span class="o">);</span>

<span class="n">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">"cID as cID1, cName as cName1, revSum as revSum1, revAvg as revAvg1"</span><span class="o">);</span>
<span class="n">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">"cID as cID2, cName as cName2, revSum as revSum2, revAvg as revAvg2"</span><span class="o">);</span>
<span class="n">Table</span> <span class="n">result</span> <span class="o">=</span> <span class="n">table1</span><span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">table2</span><span class="o">,</span> <span class="s">"revSum1 = revAvg2 &amp;&amp; cID1 &lt;&gt; cID2"</span><span class="o">);</span>

<span class="c1">// show plan with reuse info</span>
<span class="n">String</span> <span class="n">plan</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">explain</span><span class="o">(</span><span class="n">result</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">plan</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="c1">// create a BatchTableEnvironment
</span><span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getBatchTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">scan</span><span class="o">(</span><span class="s">"Orders"</span><span class="o">)</span>
    <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="ss">'cID,</span> <span class="ss">'cName)</span>
    <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="ss">'cID,</span> <span class="ss">'cName,</span> <span class="ss">'revenue.</span><span class="n">sum</span> <span class="n">as</span> <span class="ss">'revSum,</span> <span class="ss">'revenue.</span><span class="n">avg</span> <span class="n">as</span> <span class="ss">'revAvg)</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="ss">'cID </span><span class="n">as</span> <span class="ss">'cID1,</span> <span class="ss">'cName </span><span class="n">as</span> <span class="ss">'cName1,</span> <span class="ss">'revSum </span><span class="n">as</span> <span class="ss">'revSum1,</span> <span class="ss">'revAvg </span><span class="n">as</span> <span class="ss">'revAvg1)</span>
<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">table</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="ss">'cID </span><span class="n">as</span> <span class="ss">'cID2,</span> <span class="ss">'cName </span><span class="n">as</span> <span class="ss">'cName2,</span> <span class="ss">'revSum </span><span class="n">as</span> <span class="ss">'revSum2,</span> <span class="ss">'revAvg </span><span class="n">as</span> <span class="ss">'revAvg2)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">table1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">table2</span><span class="o">,</span> <span class="s">"revSum1 = revAvg2 &amp;&amp; cID1 &lt;&gt; cID2"</span><span class="o">)</span>

<span class="c1">// show plan with reuse info
</span><span class="k">val</span> <span class="n">plan</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">explain</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">plan</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>the <code class="highlighter-rouge">explain</code> result is  as follows: (only show physical plan here, sub-plan of <code class="highlighter-rouge">SortAggregate</code> is reused)</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">SortMergeJoin(where=[AND(=(revSum, revAvg0), &lt;&gt;(cID, cID0))], join=[cID, cName, revSum, revAvg, cID0, cName0, revSum0, revAvg0], joinType=[InnerJoin])
:- Exchange(distribution=[hash[revSum]])
:  +- SortAggregate(isMerge=[false], groupBy=[cID, cName], select=[cID, cName, SUM(revenue) AS revSum, AVG(revenue) AS revAvg], reuse_id=[1])
:     +- Sort(orderBy=[cID ASC, cName ASC])
:        +- Exchange(distribution=[hash[cID, cName]])
:           +- TableSourceScan(table=[[builtin, default, Orders, source: [selectedFields=[cID, cName, revenue]]]], fields=[cID, cName, revenue])
+- Exchange(distribution=[hash[revAvg]])
   +- Reused(reference_id=[1])</code></pre></figure>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h3 id="explaining-a-table">Explaining a Table</h3>

<p>The Table API provides a mechanism to explain the logical and optimized query plans to compute a <code class="highlighter-rouge">Table</code>. 
This is done through the <code class="highlighter-rouge">TableEnvironment.explain(table)</code> method. It returns a String describing three plans:</p>

<ol>
  <li>the Abstract Syntax Tree of the relational query, i.e., the unoptimized logical query plan,</li>
  <li>the optimized logical query plan, and</li>
  <li>the physical execution plan.</li>
</ol>

<p>The following code shows an example and the corresponding output:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream1</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">));</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">stream2</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span><span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">));</span>

<span class="n">Table</span> <span class="n">table1</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream1</span><span class="o">,</span> <span class="s">"count, word"</span><span class="o">);</span>
<span class="n">Table</span> <span class="n">table2</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">fromDataStream</span><span class="o">(</span><span class="n">stream2</span><span class="o">,</span> <span class="s">"count, word"</span><span class="o">);</span>
<span class="n">Table</span> <span class="n">table</span> <span class="o">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="s">"LIKE(word, 'F%')"</span><span class="o">)</span>
  <span class="o">.</span><span class="na">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">);</span>

<span class="n">String</span> <span class="n">explanation</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">explain</span><span class="o">(</span><span class="n">table</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">)</span>

<span class="k">val</span> <span class="n">table1</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">)).</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="ss">'count,</span> <span class="ss">'word)</span>
<span class="k">val</span> <span class="n">table2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"hello"</span><span class="o">)).</span><span class="n">toTable</span><span class="o">(</span><span class="n">tEnv</span><span class="o">,</span> <span class="ss">'count,</span> <span class="ss">'word)</span>
<span class="k">val</span> <span class="n">table</span> <span class="k">=</span> <span class="n">table1</span>
  <span class="o">.</span><span class="n">where</span><span class="o">(</span><span class="ss">'word.</span><span class="n">like</span><span class="o">(</span><span class="s">"F%"</span><span class="o">))</span>
  <span class="o">.</span><span class="n">unionAll</span><span class="o">(</span><span class="n">table2</span><span class="o">)</span>

<span class="k">val</span> <span class="n">explanation</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">explain</span><span class="o">(</span><span class="n">table</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">explanation</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<figure class="highlight"><pre><code class="language-text" data-lang="text">== Abstract Syntax Tree ==
LogicalUnion(all=[true])
  LogicalFilter(condition=[LIKE($1, 'F%')])
    LogicalTableScan(table=[[builtin, default, _DataStreamTable_0]])
  LogicalTableScan(table=[[builtin, default, _DataStreamTable_1]])

== Optimized Logical Plan ==
DataStreamUnion(union=[count, word])
  DataStreamCalc(select=[count, word], where=[LIKE(word, 'F%')])
    DataStreamScan(table=[[builtin, default, _DataStreamTable_0]])
  DataStreamScan(table=[[builtin, default, _DataStreamTable_1]])

== Physical Execution Plan ==
Stage 1 : Data Source
  content : collect elements with CollectionInputFormat

Stage 2 : Data Source
  content : collect elements with CollectionInputFormat

  Stage 3 : Operator
    content : from: (count, word)
    ship_strategy : REBALANCE

    Stage 4 : Operator
      content : where: (LIKE(word, 'F%')), select: (count, word)
      ship_strategy : FORWARD

      Stage 5 : Operator
        content : from: (count, word)
        ship_strategy : REBALANCE</code></pre></figure>

<h3 id="alter-table-statistics">Alter Table Statistics</h3>

<p>The Table API provides a mechanism to fetch or modify a <code class="highlighter-rouge">Table</code> statistics which we represent as a struct as <code class="highlighter-rouge">FlinkStatistic</code>.
The <code class="highlighter-rouge">FlinkStatistic</code> contains information of a flink <code class="highlighter-rouge">Table</code> as below:</p>

<ol>
  <li>The columns which can be seen as unique keys.</li>
  <li>Statistics of skewed column names and values.</li>
  <li>Column monotonicity</li>
  <li><code class="highlighter-rouge">TableStats</code> which contains a <code class="highlighter-rouge">ColumnStats</code> of each column.</li>
</ol>

<p>The <code class="highlighter-rouge">ColumnStats</code> contains information of a <code class="highlighter-rouge">Table</code> column as below:</p>

<ol>
  <li>The number of distinct values(NDV).</li>
  <li>Null values count.</li>
  <li>Average length of the column values.</li>
  <li>Max length of the column values.</li>
  <li>Max value of the column values.</li>
  <li>Min values of the column values.</li>
</ol>

<p>This statistics is very important in query optimization, Flink will try to choose the best query plan based on these statistics.</p>

<p>This following code shows how to interact with the <code class="highlighter-rouge">FlinkStatistic</code>:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">StreamTableEnvironment</span> <span class="n">tEnv</span> <span class="o">=</span> <span class="n">TableEnvironment</span><span class="o">.</span><span class="na">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Get table stats</span>
<span class="n">String</span> <span class="n">tablePath</span> <span class="o">=</span> <span class="s">"catalog1.database1.table1"</span><span class="o">;</span>
<span class="n">TableStats</span> <span class="n">tableStats</span> <span class="o">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="na">getTableStats</span><span class="o">(</span><span class="n">tablePath</span><span class="o">);</span>

<span class="c1">// modify table stats</span>
<span class="n">TableStats</span> <span class="n">tableStats1</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">Array</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">tablePath1</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">tEnv</span><span class="o">.</span><span class="na">alterTableStats</span><span class="o">(</span><span class="n">tablePath1</span><span class="o">,</span> <span class="n">tableStats1</span><span class="o">);</span></code></pre></figure>

  </div>

  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">();</span>
<span class="k">val</span> <span class="n">tEnv</span> <span class="k">=</span> <span class="nc">TableEnvironment</span><span class="o">.</span><span class="n">getTableEnvironment</span><span class="o">(</span><span class="n">env</span><span class="o">);</span>

<span class="c1">// Get table stats
</span><span class="k">val</span> <span class="n">tablePath</span> <span class="k">=</span> <span class="s">"catalog1.database1.table1"</span>
<span class="k">val</span> <span class="n">tableStats</span> <span class="k">=</span> <span class="n">tEnv</span><span class="o">.</span><span class="n">getTableStats</span><span class="o">(</span><span class="n">tablePath</span><span class="o">)</span>

<span class="c1">// modify table stats
</span><span class="k">val</span> <span class="n">tableStats1</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">tablePath1</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">tEnv</span><span class="o">.</span><span class="n">alterTableStats</span><span class="o">(</span><span class="n">tablePath1</span><span class="o">,</span> <span class="n">tableStats1</span><span class="o">)</span></code></pre></figure>

  </div>
</div>
<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>



        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//flink-china.org/doc/blink/page/js/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="//flink-china.org/doc/blink/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
